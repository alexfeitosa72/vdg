{
    "sourceFile": "logs/trata_log_pcibex.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 1,
            "patches": [
                {
                    "date": 1744555047312,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1744555082871,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -55,9 +55,9 @@\n     all_processed_data = []\r\n     base_item_number = 0\r\n     \r\n     # Use relative path for logs folder\r\n-    log_folder = os.path.join(\"logs_brutos\")\r\n+    log_folder = os.path.join(\"logs\\logs_brutos\")\r\n     base_filename = \"results_prod\"\r\n     \r\n     # Process base file and numbered files\r\n     files_to_process = [f\"{base_filename}.csv\"] + [f\"{base_filename} ({i}).csv\" for i in range(1, 10)]\r\n"
                }
            ],
            "date": 1744555047312,
            "name": "Commit-0",
            "content": "# -*- coding: utf-8 -*-\r\n\r\n\r\nimport pandas as pd\r\nfrom collections import Counter\r\nimport os\r\n\r\ndef process_log_file(file_path):\r\n    # === 1. Read CSV file ===\r\n    df = pd.read_csv(file_path, skiprows=19, header=None)\r\n    df.columns = [\r\n        \"ReceptionTime\", \"ParticipantMD5\", \"Controller\", \"ItemNumber\", \"InnerElementNumber\",\r\n        \"Label\", \"Group\", \"PennElementType\", \"PennElementName\", \"Parameter\",\r\n        \"Value\", \"EventTime\", \"Comments\"\r\n    ]\r\n    df = df[~df[\"ReceptionTime\"].astype(str).str.startswith(\"#\")].copy()\r\n    df = df[~df[\"Label\"].isin([\"TCLE\", \"instrucoes\", \"agradecimento\"])]\r\n    df.reset_index(drop=True, inplace=True)\r\n\r\n    # === 2. Extract gender data ===\r\n    genero_data = df[\r\n        (df[\"Label\"] == \"genero\") &\r\n        (df[\"PennElementName\"] == \"selecionaGenero\") &\r\n        (df[\"Parameter\"] == \"Selected\")\r\n    ][[\"ParticipantMD5\", \"Value\"]].rename(columns={\"Value\": \"Genero\"}).drop_duplicates()\r\n\r\n    # === 3. Process sentence block ===\r\n    selecoes_frases = df[\r\n        (df[\"Label\"] == \"frases\") &\r\n        (df[\"Parameter\"] == \"Selection\")\r\n    ].copy()\r\n    selecoes_frases[\"ItemNumber\"] = selecoes_frases[\"ItemNumber\"].astype(int) - 3\r\n    selecoes_frases = selecoes_frases[[\"ParticipantMD5\", \"ItemNumber\", \"Value\", \"EventTime\"]]\r\n    selecoes_frases.columns = [\"ParticipantMD5\", \"ItemNumber\", \"Classificacao\", \"Timestamp\"]\r\n\r\n    # Get start and end times\r\n    start_trials = df[(df[\"Label\"] == \"frases\") & (df[\"Parameter\"] == \"_Trial_\") & (df[\"Value\"] == \"Start\")]\r\n    end_trials = df[(df[\"Label\"] == \"frases\") & (df[\"Parameter\"] == \"_Trial_\") & (df[\"Value\"] == \"End\")]\r\n    start_trials = start_trials[[\"ParticipantMD5\", \"ItemNumber\", \"EventTime\"]].copy()\r\n    end_trials = end_trials[[\"ParticipantMD5\", \"ItemNumber\", \"EventTime\"]].copy()\r\n    start_trials[\"ItemNumber\"] = start_trials[\"ItemNumber\"].astype(int) - 3\r\n    end_trials[\"ItemNumber\"] = end_trials[\"ItemNumber\"].astype(int) - 3\r\n    start_trials.rename(columns={\"EventTime\": \"StartTime\"}, inplace=True)\r\n    end_trials.rename(columns={\"EventTime\": \"EndTime\"}, inplace=True)\r\n\r\n    # Calculate time spent\r\n    frases_final = selecoes_frases.merge(start_trials, on=[\"ParticipantMD5\", \"ItemNumber\"], how=\"left\")\r\n    frases_final = frases_final.merge(end_trials, on=[\"ParticipantMD5\", \"ItemNumber\"], how=\"left\")\r\n    frases_final[\"Tempo_Gasto\"] = ((frases_final[\"EndTime\"] - frases_final[\"StartTime\"]) / 1000).round(3)\r\n    frases_final = frases_final[[\"ParticipantMD5\", \"ItemNumber\", \"Classificacao\", \"Tempo_Gasto\", \"Timestamp\"]]\r\n    \r\n    return frases_final, genero_data\r\n\r\ndef main():\r\n    all_processed_data = []\r\n    base_item_number = 0\r\n    \r\n    # Use relative path for logs folder\r\n    log_folder = os.path.join(\"logs_brutos\")\r\n    base_filename = \"results_prod\"\r\n    \r\n    # Process base file and numbered files\r\n    files_to_process = [f\"{base_filename}.csv\"] + [f\"{base_filename} ({i}).csv\" for i in range(1, 10)]\r\n    \r\n    for filename in files_to_process:\r\n        file_path = os.path.join(log_folder, filename)\r\n        if not os.path.exists(file_path):\r\n            continue\r\n            \r\n        print(f\"Processing file: {filename}\")\r\n        try:\r\n            frases, generos = process_log_file(file_path)\r\n            \r\n            # Add offset to ItemNumber for subsequent files\r\n            frases[\"ItemNumber\"] = frases[\"ItemNumber\"] + base_item_number\r\n            \r\n            # Process this file's data independently\r\n            generos[\"GeneroCod\"] = generos[\"Genero\"].str.lower().map(lambda g: \"m\" if \"masculino\" in g else \"f\")\r\n            \r\n            # Get 4 participants of each gender for this file\r\n            ids_masculinos = generos[generos[\"GeneroCod\"] == \"m\"].head(4)[\"ParticipantMD5\"].tolist()\r\n            ids_femininos = generos[generos[\"GeneroCod\"] == \"f\"].head(4)[\"ParticipantMD5\"].tolist()\r\n            ids_selecionados = ids_femininos + ids_masculinos\r\n            \r\n            frases_filtradas = frases[frases[\"ParticipantMD5\"].isin(ids_selecionados)].copy()\r\n\r\n            # Create pivot tables with generic identifiers\r\n            pivot_class = frases_filtradas.pivot_table(\r\n                index=\"ItemNumber\", \r\n                columns=\"ParticipantMD5\", \r\n                values=\"Classificacao\", \r\n                aggfunc=\"first\"\r\n            )\r\n            \r\n            pivot_time = frases_filtradas.pivot_table(\r\n                index=\"ItemNumber\", \r\n                columns=\"ParticipantMD5\", \r\n                values=\"Tempo_Gasto\", \r\n                aggfunc=\"first\"\r\n            )\r\n\r\n            # Rename columns to generic identifiers\r\n            fem_cols = [col for col in pivot_class.columns if generos.loc[generos[\"ParticipantMD5\"] == col, \"GeneroCod\"].iloc[0] == \"f\"]\r\n            masc_cols = [col for col in pivot_class.columns if generos.loc[generos[\"ParticipantMD5\"] == col, \"GeneroCod\"].iloc[0] == \"m\"]\r\n\r\n            rename_dict_class = {}\r\n            rename_dict_time = {}\r\n            \r\n            for i, col in enumerate(fem_cols[:4], 1):\r\n                rename_dict_class[col] = f\"f{i}_class\"\r\n                rename_dict_time[col] = f\"f{i}_tempo\"\r\n            \r\n            for i, col in enumerate(masc_cols[:4], 1):\r\n                rename_dict_class[col] = f\"m{i}_class\"\r\n                rename_dict_time[col] = f\"m{i}_tempo\"\r\n\r\n            pivot_class = pivot_class.rename(columns=rename_dict_class)\r\n            pivot_time = pivot_time.rename(columns=rename_dict_time)\r\n            \r\n            frases_limitadas = pd.concat([pivot_class, pivot_time], axis=1).reset_index()\r\n\r\n            # Calculate majority classifications\r\n            def majoritaria(row, prefixo):\r\n                colunas = [f\"{prefixo}{i}_class\" for i in range(1, 5)]\r\n                respostas = [row[col] for col in colunas if pd.notna(row[col])]\r\n                if respostas:\r\n                    return Counter(respostas).most_common(1)[0][0]\r\n                return None\r\n\r\n            def contar_iguais_majoritaria(row, prefixo, majoritaria):\r\n                colunas = [f\"{prefixo}{i}_class\" for i in range(1, 5)]\r\n                return sum(1 for col in colunas if pd.notna(row[col]) and row[col] == row[majoritaria])\r\n\r\n            frases_limitadas[\"cla_maj_femi\"] = frases_limitadas.apply(lambda row: majoritaria(row, \"f\"), axis=1)\r\n            frases_limitadas[\"cla_maj_masc\"] = frases_limitadas.apply(lambda row: majoritaria(row, \"m\"), axis=1)\r\n            \r\n            frases_limitadas[\"qtd_maj_femi\"] = frases_limitadas.apply(\r\n                lambda row: contar_iguais_majoritaria(row, \"f\", \"cla_maj_femi\"), axis=1\r\n            )\r\n            frases_limitadas[\"qtd_maj_masc\"] = frases_limitadas.apply(\r\n                lambda row: contar_iguais_majoritaria(row, \"m\", \"cla_maj_masc\"), axis=1\r\n            )\r\n\r\n            # Organize columns\r\n            colunas_final = [\r\n                \"ItemNumber\",\r\n                # Majorities and quantities\r\n                \"cla_maj_femi\", \"qtd_maj_femi\",\r\n                \"cla_maj_masc\", \"qtd_maj_masc\",\r\n                # All female classifications together\r\n                \"f1_class\", \"f2_class\", \"f3_class\", \"f4_class\",\r\n                # All male classifications together\r\n                \"m1_class\", \"m2_class\", \"m3_class\", \"m4_class\",\r\n                # All time columns\r\n                \"f1_tempo\", \"f2_tempo\", \"f3_tempo\", \"f4_tempo\",\r\n                \"m1_tempo\", \"m2_tempo\", \"m3_tempo\", \"m4_tempo\"\r\n            ]\r\n\r\n            frases_formatadas = frases_limitadas[colunas_final]\r\n            all_processed_data.append(frases_formatadas)\r\n            \r\n            # Update base_item_number for next file\r\n            base_item_number = frases[\"ItemNumber\"].max()\r\n            \r\n        except Exception as e:\r\n            print(f\"Error processing {filename}: {str(e)}\")\r\n    \r\n    if all_processed_data:\r\n        # Combine all results and save\r\n        resultado_final = pd.concat(all_processed_data, ignore_index=True)\r\n        resultado_final.to_csv(\"log_tratado_completo.csv\", index=False)\r\n        print(f\"Processed {len(resultado_final)} total records\")\r\n    else:\r\n        print(\"No files were processed successfully!\")\r\n\r\nif __name__ == \"__main__\":\r\n    main()"
        }
    ]
}