{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0894bdd",
   "metadata": {},
   "source": [
    "### Concatena as frases, identificando o genero e a duração de cada resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0877a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processando bloco 1 - Arquivo: logs_brutos/results_prod.csv\n",
      "Frases encontradas no bloco 1: 150\n",
      "Arquivo salvo: logs_em_tratamento/bloco_1_concatenado.csv\n",
      "Total de classificações: 1350\n",
      "\n",
      "Processando bloco 2 - Arquivo: logs_brutos/results_prod (1).csv\n",
      "Frases encontradas no bloco 2: 150\n",
      "Arquivo salvo: logs_em_tratamento/bloco_2_concatenado.csv\n",
      "Total de classificações: 1200\n",
      "\n",
      "Processando bloco 3 - Arquivo: logs_brutos/results_prod (2).csv\n",
      "Frases encontradas no bloco 3: 150\n",
      "Arquivo salvo: logs_em_tratamento/bloco_3_concatenado.csv\n",
      "Total de classificações: 1800\n",
      "\n",
      "Processando bloco 4 - Arquivo: logs_brutos/results_prod (3).csv\n",
      "Frases encontradas no bloco 4: 150\n",
      "Arquivo salvo: logs_em_tratamento/bloco_4_concatenado.csv\n",
      "Total de classificações: 1200\n",
      "\n",
      "Processando bloco 5 - Arquivo: logs_brutos/results_prod (4).csv\n",
      "Frases encontradas no bloco 5: 150\n",
      "Arquivo salvo: logs_em_tratamento/bloco_5_concatenado.csv\n",
      "Total de classificações: 1350\n",
      "\n",
      "Processando bloco 6 - Arquivo: logs_brutos/results_prod (5).csv\n",
      "Frases encontradas no bloco 6: 150\n",
      "Arquivo salvo: logs_em_tratamento/bloco_6_concatenado.csv\n",
      "Total de classificações: 1350\n",
      "\n",
      "Processando bloco 7 - Arquivo: logs_brutos/results_prod (6).csv\n",
      "Frases encontradas no bloco 7: 150\n",
      "Arquivo salvo: logs_em_tratamento/bloco_7_concatenado.csv\n",
      "Total de classificações: 1350\n",
      "\n",
      "Processando bloco 8 - Arquivo: logs_brutos/results_prod (7).csv\n",
      "Frases encontradas no bloco 8: 150\n",
      "Arquivo salvo: logs_em_tratamento/bloco_8_concatenado.csv\n",
      "Total de classificações: 1500\n",
      "\n",
      "Processando bloco 9 - Arquivo: logs_brutos/results_prod (8).csv\n",
      "Frases encontradas no bloco 9: 150\n",
      "Arquivo salvo: logs_em_tratamento/bloco_9_concatenado.csv\n",
      "Total de classificações: 1350\n",
      "\n",
      "Processando bloco 10 - Arquivo: logs_brutos/results_prod (9).csv\n",
      "Frases encontradas no bloco 10: 115\n",
      "Arquivo salvo: logs_em_tratamento/bloco_10_concatenado.csv\n",
      "Total de classificações: 1035\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "\n",
    "def criar_pasta_tratamento():\n",
    "    \"\"\"\n",
    "    Cria a pasta logs_em_tratamento se ela não existir\n",
    "    \"\"\"\n",
    "    pasta_destino = \"logs_em_tratamento\"\n",
    "    if not os.path.exists(pasta_destino):\n",
    "        os.makedirs(pasta_destino)\n",
    "    return pasta_destino\n",
    "\n",
    "def carregar_blocos_randomizados():\n",
    "    \"\"\"\n",
    "    Carrega o arquivo com as frases e seus respectivos blocos\n",
    "    \"\"\"\n",
    "    blocos_path = \"../dados/MQD_1465_blocos_randomizados.csv\"\n",
    "    return pd.read_csv(\n",
    "        blocos_path,\n",
    "        sep='\\t',\n",
    "        quoting=csv.QUOTE_ALL,\n",
    "        quotechar='\"',\n",
    "        encoding='utf-8'\n",
    "    )\n",
    "\n",
    "def extrair_genero(df):\n",
    "    \"\"\"\n",
    "    Extrai o gênero dos participantes do arquivo de log\n",
    "    \"\"\"\n",
    "    genero_data = df[\n",
    "        (df[\"Label\"] == \"genero\") &\n",
    "        (df[\"PennElementName\"] == \"selecionaGenero\") &\n",
    "        (df[\"Parameter\"] == \"Selected\")\n",
    "    ][[\"ParticipantMD5\", \"Value\"]].copy()\n",
    "    \n",
    "    genero_data[\"GeneroCod\"] = genero_data[\"Value\"].str.lower().map(\n",
    "        lambda g: \"m\" if \"masculino\" in g else \"f\"\n",
    "    )\n",
    "    \n",
    "    return genero_data[[\"ParticipantMD5\", \"GeneroCod\"]]\n",
    "\n",
    "def processar_arquivo_log(file_path, frases_bloco, num_bloco):\n",
    "    \"\"\"\n",
    "    Processa um arquivo de log substituindo as frases originais pelas do bloco correto\n",
    "    e calcula a duração dos trials\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Lê o arquivo de log pulando as 19 linhas de cabeçalho\n",
    "        df = pd.read_csv(file_path, skiprows=19, header=None)\n",
    "        \n",
    "        # Define as colunas apenas uma vez\n",
    "        df.columns = [\n",
    "            \"ReceptionTime\", \"ParticipantMD5\", \"Controller\", \"ItemNumber\", \n",
    "            \"InnerElementNumber\", \"Label\", \"Group\", \"PennElementType\", \n",
    "            \"PennElementName\", \"Parameter\", \"Value\", \"EventTime\", \"Comments\"\n",
    "        ]\n",
    "        \n",
    "        # Debug: verifica se as colunas estão corretas\n",
    "        #print(\"\\nVerificando dados após renomeação:\")\n",
    "        #print(f\"Número de colunas: {len(df.columns)}\")\n",
    "        #print(f\"Tipos de dados:\\n{df.dtypes}\")\n",
    "        \n",
    "        # Converte EventTime para numérico\n",
    "        df[\"EventTime\"] = pd.to_numeric(df[\"EventTime\"], errors=\"coerce\")\n",
    "        \n",
    "        # Extrai informações de gênero\n",
    "        generos = extrair_genero(df)\n",
    "        \n",
    "        # Filtra eventos de início e fim dos trials\n",
    "        df_trials = df[\n",
    "            (df[\"Label\"] == \"frases\") & \n",
    "            (df[\"Value\"].isin([\"Start\", \"End\"]))\n",
    "        ].copy()\n",
    "        \n",
    "        # Ordena por participante, item e tempo\n",
    "        df_trials = df_trials.sort_values([\"ParticipantMD5\", \"ItemNumber\", \"EventTime\"])\n",
    "        \n",
    "        # Debug: verifica dados dos trials\n",
    "        #print(f\"\\nTrials encontrados: {len(df_trials)}\")\n",
    "        \n",
    "        # Calcula duração entre Start e End para cada trial\n",
    "        duracoes = []\n",
    "        for (participant, item), group in df_trials.groupby([\"ParticipantMD5\", \"ItemNumber\"]):\n",
    "            if len(group) == 2:  # Verifica se tem tanto Start quanto End\n",
    "                start_time = group[group[\"Value\"] == \"Start\"][\"EventTime\"].iloc[0]\n",
    "                end_time = group[group[\"Value\"] == \"End\"][\"EventTime\"].iloc[0]\n",
    "                duracao = (end_time - start_time) / 1000.0  # Converte para segundos\n",
    "                duracoes.append({\n",
    "                    \"ParticipantMD5\": participant,\n",
    "                    \"ItemNumber\": item,\n",
    "                    \"duracao\": duracao\n",
    "                })\n",
    "        \n",
    "        df_duracoes = pd.DataFrame(duracoes)\n",
    "        \n",
    "        # Debug: verifica durações calculadas\n",
    "        #print(f\"Durações calculadas: {len(df_duracoes)}\")\n",
    "        \n",
    "        # Filtra apenas as linhas de classificação\n",
    "        df_classificacoes = df[\n",
    "            (df[\"Label\"] == \"frases\") & \n",
    "            (df[\"Parameter\"] == \"Selection\")\n",
    "        ].copy()\n",
    "        \n",
    "        # Ajusta o ItemNumber baseado no número do bloco\n",
    "        if num_bloco == 1:\n",
    "            df_classificacoes[\"ItemNumber\"] = df_classificacoes[\"ItemNumber\"] - 3\n",
    "        else:\n",
    "            df_classificacoes[\"ItemNumber\"] = df_classificacoes[\"ItemNumber\"] - 3 + ((num_bloco - 1) * 150)\n",
    "        \n",
    "        # Merge com as frases do bloco\n",
    "        df_final = df_classificacoes.merge(\n",
    "            frases_bloco[[\"id\", \"frase\"]],\n",
    "            left_on=\"ItemNumber\",\n",
    "            right_on=\"id\",\n",
    "            how=\"inner\"\n",
    "        )\n",
    "        \n",
    "        # Adiciona informação de gênero\n",
    "        df_final = df_final.merge(\n",
    "            generos,\n",
    "            on=\"ParticipantMD5\",\n",
    "            how=\"left\"\n",
    "        )\n",
    "        \n",
    "        # Adiciona informação de duração\n",
    "        df_final = df_final.merge(\n",
    "            df_duracoes,\n",
    "            on=[\"ParticipantMD5\", \"ItemNumber\"],\n",
    "            how=\"left\"\n",
    "        )\n",
    "        \n",
    "        return df_final[[\"ParticipantMD5\", \"GeneroCod\", \"frase\", \"Value\", \"duracao\"]]\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao processar arquivo: {str(e)}\")\n",
    "        print(f\"Local do erro: {e.__traceback__.tb_lineno}\")\n",
    "        raise\n",
    "def processar_todos_arquivos():\n",
    "    \"\"\"\n",
    "    Processa todos os arquivos de log, correlacionando com os blocos corretos\n",
    "    \"\"\"\n",
    "    pasta_destino = criar_pasta_tratamento()\n",
    "    df_blocos = carregar_blocos_randomizados()\n",
    "    \n",
    "    # Para cada arquivo de log (0 a 9)\n",
    "    for i in range(10):\n",
    "        num_bloco = i + 1\n",
    "        if i == 0:\n",
    "            arquivo_origem = \"logs_brutos/results_prod.csv\"\n",
    "        else:\n",
    "            arquivo_origem = f\"logs_brutos/results_prod ({i}).csv\"\n",
    "            \n",
    "        arquivo_destino = f\"{pasta_destino}/bloco_{num_bloco}_concatenado.csv\"\n",
    "        \n",
    "        if os.path.exists(arquivo_origem):\n",
    "            print(f\"\\nProcessando bloco {num_bloco} - Arquivo: {arquivo_origem}\")\n",
    "            \n",
    "            frases_bloco = df_blocos[df_blocos['bloco'] == num_bloco].copy()\n",
    "            print(f\"Frases encontradas no bloco {num_bloco}: {len(frases_bloco)}\")\n",
    "            \n",
    "            try:\n",
    "                df_processado = processar_arquivo_log(arquivo_origem, frases_bloco, num_bloco)\n",
    "                \n",
    "                if len(df_processado) > 0:\n",
    "                    df_processado.to_csv(\n",
    "                        arquivo_destino,\n",
    "                        sep='\\t',\n",
    "                        index=False,\n",
    "                        quoting=csv.QUOTE_ALL,\n",
    "                        quotechar='\"',\n",
    "                        encoding='utf-8'\n",
    "                    )\n",
    "                    print(f\"Arquivo salvo: {arquivo_destino}\")\n",
    "                    print(f\"Total de classificações: {len(df_processado)}\")\n",
    "                else:\n",
    "                    print(f\"AVISO: Nenhuma classificação encontrada para o bloco {num_bloco}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao processar bloco {num_bloco}: {str(e)}\")\n",
    "        else:\n",
    "            print(f\"Arquivo não encontrado: {arquivo_origem}\")\n",
    "\n",
    "# Executa o processamento\n",
    "processar_todos_arquivos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47e9dd71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processando bloco 1 - Arquivo: logs_brutos/results_prod.csv\n",
      "Frases encontradas no bloco 1: 150\n",
      "Arquivo salvo: logs_em_tratamento/bloco_1_concatenado.csv\n",
      "Total de classificações: 1350\n",
      "\n",
      "Processando bloco 2 - Arquivo: logs_brutos/results_prod (1).csv\n",
      "Frases encontradas no bloco 2: 150\n",
      "Arquivo salvo: logs_em_tratamento/bloco_2_concatenado.csv\n",
      "Total de classificações: 1200\n",
      "\n",
      "Processando bloco 3 - Arquivo: logs_brutos/results_prod (2).csv\n",
      "Frases encontradas no bloco 3: 150\n",
      "Arquivo salvo: logs_em_tratamento/bloco_3_concatenado.csv\n",
      "Total de classificações: 1800\n",
      "\n",
      "Processando bloco 4 - Arquivo: logs_brutos/results_prod (3).csv\n",
      "Frases encontradas no bloco 4: 150\n",
      "Arquivo salvo: logs_em_tratamento/bloco_4_concatenado.csv\n",
      "Total de classificações: 1200\n",
      "\n",
      "Processando bloco 5 - Arquivo: logs_brutos/results_prod (4).csv\n",
      "Frases encontradas no bloco 5: 150\n",
      "Arquivo salvo: logs_em_tratamento/bloco_5_concatenado.csv\n",
      "Total de classificações: 1350\n",
      "\n",
      "Processando bloco 6 - Arquivo: logs_brutos/results_prod (5).csv\n",
      "Frases encontradas no bloco 6: 150\n",
      "Arquivo salvo: logs_em_tratamento/bloco_6_concatenado.csv\n",
      "Total de classificações: 1350\n",
      "\n",
      "Processando bloco 7 - Arquivo: logs_brutos/results_prod (6).csv\n",
      "Frases encontradas no bloco 7: 150\n",
      "Arquivo salvo: logs_em_tratamento/bloco_7_concatenado.csv\n",
      "Total de classificações: 1350\n",
      "\n",
      "Processando bloco 8 - Arquivo: logs_brutos/results_prod (7).csv\n",
      "Frases encontradas no bloco 8: 150\n",
      "Arquivo salvo: logs_em_tratamento/bloco_8_concatenado.csv\n",
      "Total de classificações: 1500\n",
      "\n",
      "Processando bloco 9 - Arquivo: logs_brutos/results_prod (8).csv\n",
      "Frases encontradas no bloco 9: 150\n",
      "Arquivo salvo: logs_em_tratamento/bloco_9_concatenado.csv\n",
      "Total de classificações: 1350\n",
      "\n",
      "Processando bloco 10 - Arquivo: logs_brutos/results_prod (9).csv\n",
      "Frases encontradas no bloco 10: 115\n",
      "Arquivo salvo: logs_em_tratamento/bloco_10_concatenado.csv\n",
      "Total de classificações: 1035\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "\n",
    "def criar_pasta_tratamento():\n",
    "    \"\"\"\n",
    "    Cria a pasta logs_em_tratamento se ela não existir\n",
    "    \"\"\"\n",
    "    pasta_destino = \"logs_em_tratamento\"\n",
    "    if not os.path.exists(pasta_destino):\n",
    "        os.makedirs(pasta_destino)\n",
    "    return pasta_destino\n",
    "\n",
    "def carregar_blocos_randomizados():\n",
    "    \"\"\"\n",
    "    Carrega o arquivo com as frases e seus respectivos blocos\n",
    "    \"\"\"\n",
    "    blocos_path = \"../dados/MQD_1465_blocos_randomizados.csv\"\n",
    "    return pd.read_csv(\n",
    "        blocos_path,\n",
    "        sep='\\t',\n",
    "        quoting=csv.QUOTE_ALL,\n",
    "        quotechar='\"',\n",
    "        encoding='utf-8'\n",
    "    )\n",
    "\n",
    "def extrair_genero(df):\n",
    "    \"\"\"\n",
    "    Extrai o gênero dos participantes do arquivo de log\n",
    "    \"\"\"\n",
    "    genero_data = df[\n",
    "        (df[\"Label\"] == \"genero\") &\n",
    "        (df[\"PennElementName\"] == \"selecionaGenero\") &\n",
    "        (df[\"Parameter\"] == \"Selected\")\n",
    "    ][[\"ParticipantMD5\", \"Value\"]].copy()\n",
    "    \n",
    "    genero_data[\"GeneroCod\"] = genero_data[\"Value\"].str.lower().map(\n",
    "        lambda g: \"m\" if \"masculino\" in g else \"f\"\n",
    "    )\n",
    "    \n",
    "    return genero_data[[\"ParticipantMD5\", \"GeneroCod\"]]\n",
    "\n",
    "def processar_arquivo_log(file_path, frases_bloco, num_bloco):\n",
    "    \"\"\"\n",
    "    Processa um arquivo de log substituindo as frases originais pelas do bloco correto\n",
    "    e calcula a duração dos trials\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Lê o arquivo de log pulando as 19 linhas de cabeçalho\n",
    "        df = pd.read_csv(file_path, skiprows=19, header=None)\n",
    "        \n",
    "        # Define as colunas apenas uma vez\n",
    "        df.columns = [\n",
    "            \"ReceptionTime\", \"ParticipantMD5\", \"Controller\", \"ItemNumber\", \n",
    "            \"InnerElementNumber\", \"Label\", \"Group\", \"PennElementType\", \n",
    "            \"PennElementName\", \"Parameter\", \"Value\", \"EventTime\", \"Comments\"\n",
    "        ]\n",
    "        \n",
    "        # Converte EventTime para numérico\n",
    "        df[\"EventTime\"] = pd.to_numeric(df[\"EventTime\"], errors=\"coerce\")\n",
    "        \n",
    "        # Extrai informações de gênero\n",
    "        generos = extrair_genero(df)\n",
    "        \n",
    "        # Filtra eventos de início e fim dos trials\n",
    "        df_trials = df[\n",
    "            (df[\"Label\"] == \"frases\") & \n",
    "            (df[\"Value\"].isin([\"Start\", \"End\"]))\n",
    "        ].copy()\n",
    "        \n",
    "        # Ajusta o ItemNumber nos trials de acordo com o bloco\n",
    "        if num_bloco == 1:\n",
    "            df_trials[\"ItemNumber\"] = df_trials[\"ItemNumber\"] - 3\n",
    "        else:\n",
    "            df_trials[\"ItemNumber\"] = df_trials[\"ItemNumber\"] - 3 + ((num_bloco - 1) * 150)\n",
    "        \n",
    "        # Ordena por participante, item e tempo\n",
    "        df_trials = df_trials.sort_values([\"ParticipantMD5\", \"ItemNumber\", \"EventTime\"])\n",
    "        \n",
    "        # Calcula duração entre Start e End para cada trial\n",
    "        duracoes = []\n",
    "        for (participant, item), group in df_trials.groupby([\"ParticipantMD5\", \"ItemNumber\"]):\n",
    "            if len(group) == 2:  # Verifica se tem tanto Start quanto End\n",
    "                start_time = group[group[\"Value\"] == \"Start\"][\"EventTime\"].iloc[0]\n",
    "                end_time = group[group[\"Value\"] == \"End\"][\"EventTime\"].iloc[0]\n",
    "                duracao = (end_time - start_time) / 1000.0  # Converte para segundos\n",
    "                duracoes.append({\n",
    "                    \"ParticipantMD5\": participant,\n",
    "                    \"ItemNumber\": item,\n",
    "                    \"duracao\": duracao\n",
    "                })\n",
    "        \n",
    "        df_duracoes = pd.DataFrame(duracoes)\n",
    "        \n",
    "        # Filtra apenas as linhas de classificação\n",
    "        df_classificacoes = df[\n",
    "            (df[\"Label\"] == \"frases\") & \n",
    "            (df[\"Parameter\"] == \"Selection\")\n",
    "        ].copy()\n",
    "        \n",
    "        # Ajusta o ItemNumber baseado no número do bloco\n",
    "        if num_bloco == 1:\n",
    "            df_classificacoes[\"ItemNumber\"] = df_classificacoes[\"ItemNumber\"] - 3\n",
    "        else:\n",
    "            df_classificacoes[\"ItemNumber\"] = df_classificacoes[\"ItemNumber\"] - 3 + ((num_bloco - 1) * 150)\n",
    "        \n",
    "        # Merge com as frases do bloco\n",
    "        df_final = df_classificacoes.merge(\n",
    "            frases_bloco[[\"id\", \"frase\"]],\n",
    "            left_on=\"ItemNumber\",\n",
    "            right_on=\"id\",\n",
    "            how=\"inner\"\n",
    "        )\n",
    "        \n",
    "        # Adiciona informação de gênero\n",
    "        df_final = df_final.merge(\n",
    "            generos,\n",
    "            on=\"ParticipantMD5\",\n",
    "            how=\"left\"\n",
    "        )\n",
    "        \n",
    "        # Adiciona informação de duração\n",
    "        df_final = df_final.merge(\n",
    "            df_duracoes,\n",
    "            on=[\"ParticipantMD5\", \"ItemNumber\"],\n",
    "            how=\"left\"\n",
    "        )\n",
    "        \n",
    "        return df_final[[\"ParticipantMD5\", \"GeneroCod\", \"frase\", \"Value\", \"duracao\"]]\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao processar arquivo: {str(e)}\")\n",
    "        print(f\"Local do erro: {e.__traceback__.tb_lineno}\")\n",
    "        raise\n",
    "\n",
    "def processar_todos_arquivos():\n",
    "    \"\"\"\n",
    "    Processa todos os arquivos de log, correlacionando com os blocos corretos\n",
    "    \"\"\"\n",
    "    pasta_destino = criar_pasta_tratamento()\n",
    "    df_blocos = carregar_blocos_randomizados()\n",
    "    \n",
    "    # Para cada arquivo de log (0 a 9)\n",
    "    for i in range(10):\n",
    "        num_bloco = i + 1\n",
    "        if i == 0:\n",
    "            arquivo_origem = \"logs_brutos/results_prod.csv\"\n",
    "        else:\n",
    "            arquivo_origem = f\"logs_brutos/results_prod ({i}).csv\"\n",
    "            \n",
    "        arquivo_destino = f\"{pasta_destino}/bloco_{num_bloco}_concatenado.csv\"\n",
    "        \n",
    "        if os.path.exists(arquivo_origem):\n",
    "            print(f\"\\nProcessando bloco {num_bloco} - Arquivo: {arquivo_origem}\")\n",
    "            \n",
    "            frases_bloco = df_blocos[df_blocos['bloco'] == num_bloco].copy()\n",
    "            print(f\"Frases encontradas no bloco {num_bloco}: {len(frases_bloco)}\")\n",
    "            \n",
    "            try:\n",
    "                df_processado = processar_arquivo_log(arquivo_origem, frases_bloco, num_bloco)\n",
    "                \n",
    "                if len(df_processado) > 0:\n",
    "                    df_processado.to_csv(\n",
    "                        arquivo_destino,\n",
    "                        sep='\\t',\n",
    "                        index=False,\n",
    "                        quoting=csv.QUOTE_ALL,\n",
    "                        quotechar='\"',\n",
    "                        encoding='utf-8'\n",
    "                    )\n",
    "                    print(f\"Arquivo salvo: {arquivo_destino}\")\n",
    "                    print(f\"Total de classificações: {len(df_processado)}\")\n",
    "                else:\n",
    "                    print(f\"AVISO: Nenhuma classificação encontrada para o bloco {num_bloco}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao processar bloco {num_bloco}: {str(e)}\")\n",
    "        else:\n",
    "            print(f\"Arquivo não encontrado: {arquivo_origem}\")\n",
    "\n",
    "# Executa o processamento\n",
    "processar_todos_arquivos()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
