{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44516909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etapa 1: Carregando arquivo de logs processados...\n",
      "Carregados 1465 registros do arquivo de logs processados.\n",
      "\n",
      "Etapa 2: Carregando e consolidando logs brutos...\n",
      "Carregando classificações de: results_prod.csv\n",
      "Carregando classificações de: results_prod (1).csv\n",
      "Carregando classificações de: results_prod (2).csv\n",
      "Carregando classificações de: results_prod (3).csv\n",
      "Carregando classificações de: results_prod (4).csv\n",
      "Carregando classificações de: results_prod (5).csv\n",
      "Carregando classificações de: results_prod (6).csv\n",
      "Carregando classificações de: results_prod (7).csv\n",
      "Carregando classificações de: results_prod (8).csv\n",
      "Carregando classificações de: results_prod (9).csv\n",
      "Carregadas 13485 classificações dos logs brutos.\n",
      "\n",
      "Etapa 3: Salvando dados consolidados...\n",
      "Dados consolidados salvos em: dados/MQD_1465_classificacoes_consolidadas.csv\n",
      "\n",
      "Estatísticas básicas:\n",
      "Total de frases classificadas: 150\n",
      "\n",
      "Classificações por gênero:\n",
      "GeneroCod\n",
      "f    6460\n",
      "m    7025\n",
      "Name: ItemNumber, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Análise de Classificações de Sentimentos\n",
    "Este script processa logs brutos e consolidados para análise inicial das classificações.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "\n",
    "def carregar_arquivo_seguro(file_path):\n",
    "    \"\"\"\n",
    "    Carrega um arquivo CSV de forma segura, tratando aspas corretamente.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(\n",
    "        file_path,\n",
    "        sep=',',\n",
    "        quoting=csv.QUOTE_ALL,\n",
    "        quotechar='\"',\n",
    "        skipinitialspace=True,\n",
    "        encoding='utf-8'\n",
    "    )\n",
    "    \n",
    "    df.columns = df.columns.str.strip()\n",
    "    df = df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def process_log_file(file_path):\n",
    "    \"\"\"\n",
    "    Processa um arquivo de log do PCIbex e extrai informações relevantes.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path, skiprows=19, header=None)\n",
    "    \n",
    "    df.columns = [\n",
    "        \"ReceptionTime\", \"ParticipantMD5\", \"Controller\", \"ItemNumber\", \"InnerElementNumber\",\n",
    "        \"Label\", \"Group\", \"PennElementType\", \"PennElementName\", \"Parameter\",\n",
    "        \"Value\", \"EventTime\", \"Comments\"\n",
    "    ]\n",
    "    \n",
    "    df = df[~df[\"ReceptionTime\"].astype(str).str.startswith(\"#\")].copy()\n",
    "    df = df[~df[\"Label\"].isin([\"TCLE\", \"instrucoes\", \"agradecimento\"])]\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Extração de dados de gênero\n",
    "    genero_data = df[\n",
    "        (df[\"Label\"] == \"genero\") &\n",
    "        (df[\"PennElementName\"] == \"selecionaGenero\") &\n",
    "        (df[\"Parameter\"] == \"Selected\")\n",
    "    ][[\"ParticipantMD5\", \"Value\"]].rename(columns={\"Value\": \"Genero\"}).drop_duplicates()\n",
    "    \n",
    "    # Processamento das classificações\n",
    "    selecoes_frases = df[\n",
    "        (df[\"Label\"] == \"frases\") &\n",
    "        (df[\"Parameter\"] == \"Selection\")\n",
    "    ].copy()\n",
    "    \n",
    "    selecoes_frases[\"ItemNumber\"] = selecoes_frases[\"ItemNumber\"].astype(int) - 3\n",
    "    selecoes_frases = selecoes_frases[[\"ParticipantMD5\", \"ItemNumber\", \"Value\", \"EventTime\"]]\n",
    "    selecoes_frases.columns = [\"ParticipantMD5\", \"ItemNumber\", \"Classificacao\", \"Timestamp\"]\n",
    "    \n",
    "    return selecoes_frases, genero_data\n",
    "\n",
    "def carregar_logs_brutos(log_folder, base_filename=\"results_prod\", num_files=10):\n",
    "    \"\"\"\n",
    "    Carrega e consolida todos os logs brutos disponíveis.\n",
    "    \"\"\"\n",
    "    all_raw_classifications = []\n",
    "    files_to_process = [f\"{base_filename}.csv\"] + [f\"{base_filename} ({i}).csv\" for i in range(1, num_files)]\n",
    "    \n",
    "    for filename in files_to_process:\n",
    "        file_path = os.path.join(log_folder, filename)\n",
    "        if not os.path.exists(file_path):\n",
    "            continue\n",
    "            \n",
    "        print(f\"Carregando classificações de: {filename}\")\n",
    "        \n",
    "        try:\n",
    "            frases, generos = process_log_file(file_path)\n",
    "            generos[\"GeneroCod\"] = generos[\"Genero\"].str.lower().map(lambda g: \"m\" if \"masculino\" in g else \"f\")\n",
    "            \n",
    "            frases_com_genero = frases.merge(\n",
    "                generos[[\"ParticipantMD5\", \"GeneroCod\"]], \n",
    "                on=\"ParticipantMD5\", \n",
    "                how=\"left\"\n",
    "            )\n",
    "            all_raw_classifications.append(frases_com_genero)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao processar {filename}: {str(e)}\")\n",
    "    \n",
    "    if all_raw_classifications:\n",
    "        return pd.concat(all_raw_classifications, ignore_index=True)\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Função principal que orquestra todo o processamento.\n",
    "    \"\"\"\n",
    "    # Definição de caminhos\n",
    "    log_folder = \"logs/logs_brutos\"\n",
    "    log_processado_path = \"dados/MQD_1465_log_processado.csv\"\n",
    "    output_consolidado_path = \"dados/MQD_1465_classificacoes_consolidadas.csv\"\n",
    "    \n",
    "    # Etapa 1: Carregar arquivo de logs processados\n",
    "    print(\"Etapa 1: Carregando arquivo de logs processados...\")\n",
    "    df_processado = carregar_arquivo_seguro(log_processado_path)\n",
    "    print(f\"Carregados {len(df_processado)} registros do arquivo de logs processados.\")\n",
    "    \n",
    "    # Etapa 2: Carregar e consolidar logs brutos\n",
    "    print(\"\\nEtapa 2: Carregando e consolidando logs brutos...\")\n",
    "    todas_classificacoes = carregar_logs_brutos(log_folder)\n",
    "    print(f\"Carregadas {len(todas_classificacoes)} classificações dos logs brutos.\")\n",
    "    \n",
    "    # Etapa 3: Salvar consolidação\n",
    "    print(\"\\nEtapa 3: Salvando dados consolidados...\")\n",
    "    todas_classificacoes.to_csv(output_consolidado_path, index=False)\n",
    "    print(f\"Dados consolidados salvos em: {output_consolidado_path}\")\n",
    "    \n",
    "    # Estatísticas básicas\n",
    "    print(\"\\nEstatísticas básicas:\")\n",
    "    print(f\"Total de frases classificadas: {len(todas_classificacoes['ItemNumber'].unique())}\")\n",
    "    print(\"\\nClassificações por gênero:\")\n",
    "    print(todas_classificacoes.groupby('GeneroCod')['ItemNumber'].count())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
