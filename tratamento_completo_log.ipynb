{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96984627",
   "metadata": {},
   "source": [
    "### Unificacao dos tratamentos de logs para a geracao de um csv processado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b549a26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etapa 1: Processando logs brutos...\n",
      "Processando arquivo: results_prod.csv\n",
      "Processando arquivo: results_prod (1).csv\n",
      "Processando arquivo: results_prod (2).csv\n",
      "Processando arquivo: results_prod (3).csv\n",
      "Processando arquivo: results_prod (4).csv\n",
      "Processando arquivo: results_prod (5).csv\n",
      "Processando arquivo: results_prod (6).csv\n",
      "Processando arquivo: results_prod (7).csv\n",
      "Processando arquivo: results_prod (8).csv\n",
      "Processando arquivo: results_prod (9).csv\n",
      "Logs processados salvos em: dados/MQD_1465_log_original.csv\n",
      "\n",
      "Etapa 2: Combinando com arquivo de frases randomizadas...\n",
      "\n",
      "Etapa 3: Salvando resultado final...\n",
      "Arquivo salvo em: dados/MQD_1465_log_processado.csv\n",
      "\n",
      "Processamento concluído. Total de 1465 registros processados.\n",
      "Distribuição de classificações femininas: {'positiva': 514, 'negativa': 503, 'neutra': 448}\n",
      "Distribuição de classificações masculinas: {'positiva': 619, 'negativa': 514, 'neutra': 332}\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Processamento de Logs PCIbex - Análise de Sentimentos\n",
    "Este script processa logs brutos do PCIbex para um experimento de classificação de frases,\n",
    "extrai informações sobre gênero dos participantes, suas classificações e tempos de resposta,\n",
    "e combina os resultados com o arquivo de frases randomizadas.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "from collections import Counter\n",
    "\n",
    "def process_log_file(file_path):\n",
    "    \"\"\"\n",
    "    Processa um arquivo de log do PCIbex e extrai informações relevantes.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Caminho para o arquivo de log\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (DataFrame com classificações e tempos, DataFrame com dados de gênero)\n",
    "    \"\"\"\n",
    "    # === 1. Leitura do arquivo CSV ===\n",
    "    # Pula as primeiras 19 linhas que contêm metadados não relevantes\n",
    "    df = pd.read_csv(file_path, skiprows=19, header=None)\n",
    "    \n",
    "    # Define nomes para as colunas\n",
    "    df.columns = [\n",
    "        \"ReceptionTime\", \"ParticipantMD5\", \"Controller\", \"ItemNumber\", \"InnerElementNumber\",\n",
    "        \"Label\", \"Group\", \"PennElementType\", \"PennElementName\", \"Parameter\",\n",
    "        \"Value\", \"EventTime\", \"Comments\"\n",
    "    ]\n",
    "    \n",
    "    # Remove linhas de comentários e labels irrelevantes\n",
    "    df = df[~df[\"ReceptionTime\"].astype(str).str.startswith(\"#\")].copy()\n",
    "    df = df[~df[\"Label\"].isin([\"TCLE\", \"instrucoes\", \"agradecimento\"])]\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # === 2. Extração de dados de gênero ===\n",
    "    genero_data = df[\n",
    "        (df[\"Label\"] == \"genero\") &\n",
    "        (df[\"PennElementName\"] == \"selecionaGenero\") &\n",
    "        (df[\"Parameter\"] == \"Selected\")\n",
    "    ][[\"ParticipantMD5\", \"Value\"]].rename(columns={\"Value\": \"Genero\"}).drop_duplicates()\n",
    "    \n",
    "    # === 3. Processamento do bloco de frases ===\n",
    "    # Extrai as classificações (positiva, negativa, neutra)\n",
    "    selecoes_frases = df[\n",
    "        (df[\"Label\"] == \"frases\") &\n",
    "        (df[\"Parameter\"] == \"Selection\")\n",
    "    ].copy()\n",
    "    \n",
    "    # Ajusta o ItemNumber (subtrai 3 para alinhar com a numeração correta)\n",
    "    selecoes_frases[\"ItemNumber\"] = selecoes_frases[\"ItemNumber\"].astype(int) - 3\n",
    "    selecoes_frases = selecoes_frases[[\"ParticipantMD5\", \"ItemNumber\", \"Value\", \"EventTime\"]]\n",
    "    selecoes_frases.columns = [\"ParticipantMD5\", \"ItemNumber\", \"Classificacao\", \"Timestamp\"]\n",
    "    \n",
    "    # Obtém tempos de início e fim para calcular o tempo gasto\n",
    "    start_trials = df[(df[\"Label\"] == \"frases\") & (df[\"Parameter\"] == \"_Trial_\") & (df[\"Value\"] == \"Start\")]\n",
    "    end_trials = df[(df[\"Label\"] == \"frases\") & (df[\"Parameter\"] == \"_Trial_\") & (df[\"Value\"] == \"End\")]\n",
    "    \n",
    "    start_trials = start_trials[[\"ParticipantMD5\", \"ItemNumber\", \"EventTime\"]].copy()\n",
    "    end_trials = end_trials[[\"ParticipantMD5\", \"ItemNumber\", \"EventTime\"]].copy()\n",
    "    \n",
    "    start_trials[\"ItemNumber\"] = start_trials[\"ItemNumber\"].astype(int) - 3\n",
    "    end_trials[\"ItemNumber\"] = end_trials[\"ItemNumber\"].astype(int) - 3\n",
    "    \n",
    "    start_trials.rename(columns={\"EventTime\": \"StartTime\"}, inplace=True)\n",
    "    end_trials.rename(columns={\"EventTime\": \"EndTime\"}, inplace=True)\n",
    "    \n",
    "    # Calcula o tempo gasto em cada classificação (em segundos)\n",
    "    frases_final = selecoes_frases.merge(start_trials, on=[\"ParticipantMD5\", \"ItemNumber\"], how=\"left\")\n",
    "    frases_final = frases_final.merge(end_trials, on=[\"ParticipantMD5\", \"ItemNumber\"], how=\"left\")\n",
    "    frases_final[\"Tempo_Gasto\"] = ((frases_final[\"EndTime\"] - frases_final[\"StartTime\"]) / 1000).round(3)\n",
    "    \n",
    "    frases_final = frases_final[[\"ParticipantMD5\", \"ItemNumber\", \"Classificacao\", \"Tempo_Gasto\", \"Timestamp\"]]\n",
    "    \n",
    "    return frases_final, genero_data\n",
    "\n",
    "def process_all_logs(log_folder, base_filename=\"results_prod\", num_files=10):\n",
    "    \"\"\"\n",
    "    Processa todos os arquivos de log e seleciona 4 participantes de cada gênero por arquivo.\n",
    "    \n",
    "    Args:\n",
    "        log_folder (str): Pasta contendo os logs brutos\n",
    "        base_filename (str): Nome base dos arquivos de log\n",
    "        num_files (int): Número de arquivos numerados a processar\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Dados processados de todos os arquivos\n",
    "    \"\"\"\n",
    "    all_processed_data = []\n",
    "    base_item_number = 0\n",
    "    \n",
    "    # Lista de arquivos a processar (arquivo base + numerados)\n",
    "    files_to_process = [f\"{base_filename}.csv\"] + [f\"{base_filename} ({i}).csv\" for i in range(1, num_files)]\n",
    "    \n",
    "    for filename in files_to_process:\n",
    "        file_path = os.path.join(log_folder, filename)\n",
    "        if not os.path.exists(file_path):\n",
    "            continue\n",
    "            \n",
    "        print(f\"Processando arquivo: {filename}\")\n",
    "        \n",
    "        try:\n",
    "            # Processa o arquivo atual\n",
    "            frases, generos = process_log_file(file_path)\n",
    "            \n",
    "            # Adiciona offset ao ItemNumber para arquivos subsequentes\n",
    "            frases[\"ItemNumber\"] = frases[\"ItemNumber\"] + base_item_number\n",
    "            \n",
    "            # Codifica o gênero (m/f)\n",
    "            generos[\"GeneroCod\"] = generos[\"Genero\"].str.lower().map(lambda g: \"m\" if \"masculino\" in g else \"f\")\n",
    "            \n",
    "            # Seleciona 4 participantes de cada gênero para este arquivo\n",
    "            ids_masculinos = generos[generos[\"GeneroCod\"] == \"m\"].head(4)[\"ParticipantMD5\"].tolist()\n",
    "            ids_femininos = generos[generos[\"GeneroCod\"] == \"f\"].head(4)[\"ParticipantMD5\"].tolist()\n",
    "            ids_selecionados = ids_femininos + ids_masculinos\n",
    "            \n",
    "            frases_filtradas = frases[frases[\"ParticipantMD5\"].isin(ids_selecionados)].copy()\n",
    "            \n",
    "            # Cria tabelas pivot com identificadores genéricos\n",
    "            pivot_class = frases_filtradas.pivot_table(\n",
    "                index=\"ItemNumber\",\n",
    "                columns=\"ParticipantMD5\",\n",
    "                values=\"Classificacao\",\n",
    "                aggfunc=\"first\"\n",
    "            )\n",
    "            \n",
    "            pivot_time = frases_filtradas.pivot_table(\n",
    "                index=\"ItemNumber\",\n",
    "                columns=\"ParticipantMD5\",\n",
    "                values=\"Tempo_Gasto\",\n",
    "                aggfunc=\"first\"\n",
    "            )\n",
    "            \n",
    "            # Renomeia colunas para identificadores genéricos (f1, f2, m1, m2, etc.)\n",
    "            fem_cols = [col for col in pivot_class.columns if generos.loc[generos[\"ParticipantMD5\"] == col, \"GeneroCod\"].iloc[0] == \"f\"]\n",
    "            masc_cols = [col for col in pivot_class.columns if generos.loc[generos[\"ParticipantMD5\"] == col, \"GeneroCod\"].iloc[0] == \"m\"]\n",
    "            \n",
    "            rename_dict_class = {}\n",
    "            rename_dict_time = {}\n",
    "            \n",
    "            for i, col in enumerate(fem_cols[:4], 1):\n",
    "                rename_dict_class[col] = f\"f{i}_class\"\n",
    "                rename_dict_time[col] = f\"f{i}_tempo\"\n",
    "                \n",
    "            for i, col in enumerate(masc_cols[:4], 1):\n",
    "                rename_dict_class[col] = f\"m{i}_class\"\n",
    "                rename_dict_time[col] = f\"m{i}_tempo\"\n",
    "                \n",
    "            pivot_class = pivot_class.rename(columns=rename_dict_class)\n",
    "            pivot_time = pivot_time.rename(columns=rename_dict_time)\n",
    "            \n",
    "            frases_limitadas = pd.concat([pivot_class, pivot_time], axis=1).reset_index()\n",
    "            \n",
    "            # Calcula classificações majoritárias\n",
    "            def majoritaria(row, prefixo):\n",
    "                colunas = [f\"{prefixo}{i}_class\" for i in range(1, 5)]\n",
    "                respostas = [row[col] for col in colunas if pd.notna(row[col])]\n",
    "                if respostas:\n",
    "                    return Counter(respostas).most_common(1)[0][0]\n",
    "                return None\n",
    "                \n",
    "            def contar_iguais_majoritaria(row, prefixo, majoritaria):\n",
    "                colunas = [f\"{prefixo}{i}_class\" for i in range(1, 5)]\n",
    "                return sum(1 for col in colunas if pd.notna(row[col]) and row[col] == row[majoritaria])\n",
    "                \n",
    "            frases_limitadas[\"cla_maj_femi\"] = frases_limitadas.apply(lambda row: majoritaria(row, \"f\"), axis=1)\n",
    "            frases_limitadas[\"cla_maj_masc\"] = frases_limitadas.apply(lambda row: majoritaria(row, \"m\"), axis=1)\n",
    "            \n",
    "            frases_limitadas[\"qtd_maj_femi\"] = frases_limitadas.apply(\n",
    "                lambda row: contar_iguais_majoritaria(row, \"f\", \"cla_maj_femi\"), axis=1\n",
    "            )\n",
    "            \n",
    "            frases_limitadas[\"qtd_maj_masc\"] = frases_limitadas.apply(\n",
    "                lambda row: contar_iguais_majoritaria(row, \"m\", \"cla_maj_masc\"), axis=1\n",
    "            )\n",
    "            \n",
    "            # Organiza as colunas\n",
    "            colunas_final = [\n",
    "                \"ItemNumber\",\n",
    "                # Majoritárias e quantidades\n",
    "                \"cla_maj_femi\", \"qtd_maj_femi\",\n",
    "                \"cla_maj_masc\", \"qtd_maj_masc\",\n",
    "                # Classificações femininas\n",
    "                \"f1_class\", \"f2_class\", \"f3_class\", \"f4_class\",\n",
    "                # Classificações masculinas\n",
    "                \"m1_class\", \"m2_class\", \"m3_class\", \"m4_class\",\n",
    "                # Colunas de tempo\n",
    "                \"f1_tempo\", \"f2_tempo\", \"f3_tempo\", \"f4_tempo\",\n",
    "                \"m1_tempo\", \"m2_tempo\", \"m3_tempo\", \"m4_tempo\"\n",
    "            ]\n",
    "            \n",
    "            frases_formatadas = frases_limitadas[colunas_final]\n",
    "            all_processed_data.append(frases_formatadas)\n",
    "            \n",
    "            # Atualiza base_item_number para o próximo arquivo\n",
    "            base_item_number = frases[\"ItemNumber\"].max()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao processar {filename}: {str(e)}\")\n",
    "            \n",
    "    if all_processed_data:\n",
    "        # Combina todos os resultados\n",
    "        resultado_final = pd.concat(all_processed_data, ignore_index=True)\n",
    "        return resultado_final\n",
    "    else:\n",
    "        print(\"Nenhum arquivo foi processado com sucesso!\")\n",
    "        return None\n",
    "\n",
    "def merge_with_phrases(log_df, phrases_file):\n",
    "    \"\"\"\n",
    "    Combina o log processado com o arquivo de frases randomizadas.\n",
    "    \n",
    "    Args:\n",
    "        log_df (DataFrame): DataFrame com os logs processados\n",
    "        phrases_file (str): Caminho para o arquivo de frases randomizadas\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: DataFrame combinado com frases e classificações\n",
    "    \"\"\"\n",
    "    # Detecção automática do delimitador do arquivo de frases\n",
    "    with open(phrases_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        sample = f.read(2048)\n",
    "    \n",
    "    sniffer = csv.Sniffer()\n",
    "    dialect = sniffer.sniff(sample)\n",
    "    \n",
    "    # Lê o arquivo de frases randomizadas\n",
    "    df_randomizado = pd.read_csv(phrases_file, sep=dialect.delimiter)\n",
    "    \n",
    "    # Remove espaços em branco dos nomes das colunas\n",
    "    df_randomizado.columns = df_randomizado.columns.str.strip()\n",
    "    log_df.columns = log_df.columns.str.strip()\n",
    "    \n",
    "    # Garante a coluna ID_Random\n",
    "    if \"ID_Random\" not in df_randomizado.columns:\n",
    "        df_randomizado.insert(0, \"ID_Random\", range(1, len(df_randomizado) + 1))\n",
    "    \n",
    "    # Merge pelo índice\n",
    "    df_log_completo = pd.merge(\n",
    "        log_df,\n",
    "        df_randomizado[[\"ID_Random\", \"frase\"]],\n",
    "        left_on=\"ItemNumber\",\n",
    "        right_on=\"ID_Random\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    \n",
    "    # Reorganiza as colunas\n",
    "    colunas = df_log_completo.columns.tolist()\n",
    "    idx_item = colunas.index(\"ItemNumber\")\n",
    "    colunas_organizadas = colunas[:idx_item + 1] + [\"frase\"] + [col for col in colunas if col not in [\"ItemNumber\", \"frase\", \"ID_Random\"]]\n",
    "    df_log_completo = df_log_completo[colunas_organizadas]\n",
    "    \n",
    "    return df_log_completo\n",
    "\n",
    "def save_csv_with_protected_phrases(df, output_path):\n",
    "    \"\"\"\n",
    "    Salva o DataFrame como CSV com aspas protegendo a coluna de frases.\n",
    "    \n",
    "    Args:\n",
    "        df (DataFrame): DataFrame a ser salvo\n",
    "        output_path (str): Caminho para o arquivo de saída\n",
    "    \"\"\"\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\",\".join(df.columns.tolist()) + \"\\n\")\n",
    "        for _, row in df.iterrows():\n",
    "            linha = []\n",
    "            for col in df.columns:\n",
    "                val = row[col]\n",
    "                if col == \"frase\":\n",
    "                    val = str(val)\n",
    "                    if not (val.startswith('\"') and val.endswith('\"')):\n",
    "                        val = f'\"{val}\"'\n",
    "                linha.append(str(val))\n",
    "            f.write(\",\".join(linha) + \"\\n\")\n",
    "    \n",
    "    print(f\"Arquivo salvo em: {output_path}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Função principal que orquestra todo o processamento.\n",
    "    \"\"\"\n",
    "    # Definição de caminhos\n",
    "    log_folder = \"logs/logs_brutos\"\n",
    "    randomizado_path = \"dados/MQD_1465_randomizado.csv\"\n",
    "    output_log_path = \"dados/MQD_1465_log_original.csv\"\n",
    "    output_final_path = \"dados/MQD_1465_log_processado.csv\"\n",
    "    \n",
    "    # Etapa 1: Processar todos os logs\n",
    "    print(\"Etapa 1: Processando logs brutos...\")\n",
    "    resultado_logs = process_all_logs(log_folder)\n",
    "    \n",
    "    if resultado_logs is not None:\n",
    "        # Salva o resultado intermediário (logs processados sem frases)\n",
    "        resultado_logs.to_csv(output_log_path, index=False)\n",
    "        print(f\"Logs processados salvos em: {output_log_path}\")\n",
    "        \n",
    "        # Etapa 2: Combinar com o arquivo de frases\n",
    "        print(\"\\nEtapa 2: Combinando com arquivo de frases randomizadas...\")\n",
    "        resultado_final = merge_with_phrases(resultado_logs, randomizado_path)\n",
    "        \n",
    "        # Etapa 3: Salvar o resultado final com frases protegidas\n",
    "        print(\"\\nEtapa 3: Salvando resultado final...\")\n",
    "        save_csv_with_protected_phrases(resultado_final, output_final_path)\n",
    "        \n",
    "        # Exibir estatísticas finais\n",
    "        print(f\"\\nProcessamento concluído. Total de {len(resultado_final)} registros processados.\")\n",
    "        print(f\"Distribuição de classificações femininas: {resultado_final['cla_maj_femi'].value_counts().to_dict()}\")\n",
    "        print(f\"Distribuição de classificações masculinas: {resultado_final['cla_maj_masc'].value_counts().to_dict()}\")\n",
    "    else:\n",
    "        print(\"Não foi possível processar os logs. Verifique os arquivos de entrada.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594ef23c",
   "metadata": {},
   "source": [
    "### Tratamento dos empates para identificacao da classe majoritaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64c524d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etapa 1: Carregando arquivo de logs processados...\n",
      "Carregados 1465 registros do arquivo de logs processados.\n",
      "\n",
      "Etapa 2: Carregando logs brutos para buscar classificações adicionais...\n",
      "Carregando classificações de: results_prod.csv\n",
      "Carregando classificações de: results_prod (1).csv\n",
      "Carregando classificações de: results_prod (2).csv\n",
      "Carregando classificações de: results_prod (3).csv\n",
      "Carregando classificações de: results_prod (4).csv\n",
      "Carregando classificações de: results_prod (5).csv\n",
      "Carregando classificações de: results_prod (6).csv\n",
      "Carregando classificações de: results_prod (7).csv\n",
      "Carregando classificações de: results_prod (8).csv\n",
      "Carregando classificações de: results_prod (9).csv\n",
      "Carregadas 13485 classificações dos logs brutos.\n",
      "\n",
      "Etapa 3: Resolvendo empates nas classificações...\n",
      "\n",
      "Etapa 4: Salvando resultados...\n",
      "Arquivo salvo em: dados/MQD_1465_desempatado.csv\n",
      "Frases desempatadas salvas em: dados/frases_desempatadas.csv\n",
      "\n",
      "Estatísticas de classificação:\n",
      "- Frases empatadas femininas: 227\n",
      "- Frases empatadas masculinas: 140\n",
      "- Frases desempatadas femininas: 0\n",
      "- Frases desempatadas masculinas: 23\n",
      "- Total de frases ainda empatadas: 367\n",
      "- Total de frases com classes majoritárias definidas: 1098\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Tratamento de Empates em Classificações de Sentimentos - Versão Corrigida\n",
    "Este script analisa o arquivo de logs processados, identifica empates reais nas classificações\n",
    "por gênero (apenas casos 2-2), tenta resolvê-los buscando classificações adicionais, e gera \n",
    "um relatório das frases que foram desempatadas com sucesso.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "from collections import Counter\n",
    "\n",
    "def carregar_arquivo_seguro(file_path):\n",
    "    \"\"\"\n",
    "    Carrega um arquivo CSV de forma segura, tratando aspas corretamente.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Caminho para o arquivo CSV\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: DataFrame pandas com os dados do arquivo\n",
    "    \"\"\"\n",
    "    # Carrega o arquivo com os parâmetros corretos para lidar com aspas nas frases\n",
    "    df = pd.read_csv(\n",
    "        file_path,\n",
    "        sep=',',\n",
    "        quoting=csv.QUOTE_ALL,\n",
    "        quotechar='\"',\n",
    "        skipinitialspace=True,\n",
    "        encoding='utf-8'\n",
    "    )\n",
    "    \n",
    "    # Limpa os nomes das colunas e valores\n",
    "    df.columns = df.columns.str.strip()\n",
    "    df = df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def verificar_empate_exato(classificacoes):\n",
    "    \"\"\"\n",
    "    Verifica se há um empate exato (2-2) nas classificações.\n",
    "    \n",
    "    Args:\n",
    "        classificacoes (list): Lista de classificações\n",
    "        \n",
    "    Returns:\n",
    "        bool: True se houver empate exato (2-2), False caso contrário\n",
    "    \"\"\"\n",
    "    if len(classificacoes) != 4:\n",
    "        return False\n",
    "        \n",
    "    counter = Counter(classificacoes)\n",
    "    \n",
    "    # Verifica se há exatamente duas classificações diferentes\n",
    "    if len(counter) != 2:\n",
    "        return False\n",
    "    \n",
    "    # Verifica se ambas as classificações têm exatamente 2 ocorrências cada\n",
    "    valores = list(counter.values())\n",
    "    return valores[0] == 2 and valores[1] == 2\n",
    "\n",
    "def carregar_logs_brutos(log_folder, base_filename=\"results_prod\", num_files=10):\n",
    "    \"\"\"\n",
    "    Carrega todos os logs brutos para buscar classificações adicionais.\n",
    "    \n",
    "    Args:\n",
    "        log_folder (str): Pasta contendo os logs brutos\n",
    "        base_filename (str): Nome base dos arquivos de log\n",
    "        num_files (int): Número de arquivos numerados a processar\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: DataFrame com todas as classificações disponíveis\n",
    "    \"\"\"\n",
    "    all_raw_classifications = []\n",
    "    \n",
    "    # Lista de arquivos a processar (arquivo base + numerados)\n",
    "    files_to_process = [f\"{base_filename}.csv\"] + [f\"{base_filename} ({i}).csv\" for i in range(1, num_files)]\n",
    "    \n",
    "    for filename in files_to_process:\n",
    "        file_path = os.path.join(log_folder, filename)\n",
    "        if not os.path.exists(file_path):\n",
    "            continue\n",
    "            \n",
    "        print(f\"Carregando classificações de: {filename}\")\n",
    "        \n",
    "        try:\n",
    "            # Processa o arquivo atual\n",
    "            frases, generos = process_log_file(file_path)\n",
    "            \n",
    "            # Codifica o gênero (m/f)\n",
    "            generos[\"GeneroCod\"] = generos[\"Genero\"].str.lower().map(lambda g: \"m\" if \"masculino\" in g else \"f\")\n",
    "            \n",
    "            # Combina classificações com informações de gênero\n",
    "            frases_com_genero = frases.merge(\n",
    "                generos[[\"ParticipantMD5\", \"GeneroCod\"]], \n",
    "                on=\"ParticipantMD5\", \n",
    "                how=\"left\"\n",
    "            )\n",
    "            all_raw_classifications.append(frases_com_genero)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao processar {filename}: {str(e)}\")\n",
    "    \n",
    "    if all_raw_classifications:\n",
    "        return pd.concat(all_raw_classifications, ignore_index=True)\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def process_log_file(file_path):\n",
    "    \"\"\"\n",
    "    Processa um arquivo de log do PCIbex e extrai informações relevantes.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Caminho para o arquivo de log\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (DataFrame com classificações e tempos, DataFrame com dados de gênero)\n",
    "    \"\"\"\n",
    "    # === 1. Leitura do arquivo CSV ===\n",
    "    # Pula as primeiras 19 linhas que contêm metadados não relevantes\n",
    "    df = pd.read_csv(file_path, skiprows=19, header=None)\n",
    "    \n",
    "    # Define nomes para as colunas\n",
    "    df.columns = [\n",
    "        \"ReceptionTime\", \"ParticipantMD5\", \"Controller\", \"ItemNumber\", \"InnerElementNumber\",\n",
    "        \"Label\", \"Group\", \"PennElementType\", \"PennElementName\", \"Parameter\",\n",
    "        \"Value\", \"EventTime\", \"Comments\"\n",
    "    ]\n",
    "    \n",
    "    # Remove linhas de comentários e labels irrelevantes\n",
    "    df = df[~df[\"ReceptionTime\"].astype(str).str.startswith(\"#\")].copy()\n",
    "    df = df[~df[\"Label\"].isin([\"TCLE\", \"instrucoes\", \"agradecimento\"])]\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # === 2. Extração de dados de gênero ===\n",
    "    genero_data = df[\n",
    "        (df[\"Label\"] == \"genero\") &\n",
    "        (df[\"PennElementName\"] == \"selecionaGenero\") &\n",
    "        (df[\"Parameter\"] == \"Selected\")\n",
    "    ][[\"ParticipantMD5\", \"Value\"]].rename(columns={\"Value\": \"Genero\"}).drop_duplicates()\n",
    "    \n",
    "    # === 3. Processamento do bloco de frases ===\n",
    "    # Extrai as classificações (positiva, negativa, neutra)\n",
    "    selecoes_frases = df[\n",
    "        (df[\"Label\"] == \"frases\") &\n",
    "        (df[\"Parameter\"] == \"Selection\")\n",
    "    ].copy()\n",
    "    \n",
    "    # Ajusta o ItemNumber (subtrai 3 para alinhar com a numeração correta)\n",
    "    selecoes_frases[\"ItemNumber\"] = selecoes_frases[\"ItemNumber\"].astype(int) - 3\n",
    "    selecoes_frases = selecoes_frases[[\"ParticipantMD5\", \"ItemNumber\", \"Value\", \"EventTime\"]]\n",
    "    selecoes_frases.columns = [\"ParticipantMD5\", \"ItemNumber\", \"Classificacao\", \"Timestamp\"]\n",
    "    \n",
    "    # Obtém tempos de início e fim para calcular o tempo gasto\n",
    "    start_trials = df[(df[\"Label\"] == \"frases\") & (df[\"Parameter\"] == \"_Trial_\") & (df[\"Value\"] == \"Start\")]\n",
    "    end_trials = df[(df[\"Label\"] == \"frases\") & (df[\"Parameter\"] == \"_Trial_\") & (df[\"Value\"] == \"End\")]\n",
    "    \n",
    "    start_trials = start_trials[[\"ParticipantMD5\", \"ItemNumber\", \"EventTime\"]].copy()\n",
    "    end_trials = end_trials[[\"ParticipantMD5\", \"ItemNumber\", \"EventTime\"]].copy()\n",
    "    \n",
    "    start_trials[\"ItemNumber\"] = start_trials[\"ItemNumber\"].astype(int) - 3\n",
    "    end_trials[\"ItemNumber\"] = end_trials[\"ItemNumber\"].astype(int) - 3\n",
    "    \n",
    "    start_trials.rename(columns={\"EventTime\": \"StartTime\"}, inplace=True)\n",
    "    end_trials.rename(columns={\"EventTime\": \"EndTime\"}, inplace=True)\n",
    "    \n",
    "    # Calcula o tempo gasto em cada classificação (em segundos)\n",
    "    frases_final = selecoes_frases.merge(start_trials, on=[\"ParticipantMD5\", \"ItemNumber\"], how=\"left\")\n",
    "    frases_final = frases_final.merge(end_trials, on=[\"ParticipantMD5\", \"ItemNumber\"], how=\"left\")\n",
    "    frases_final[\"Tempo_Gasto\"] = ((frases_final[\"EndTime\"] - frases_final[\"StartTime\"]) / 1000).round(3)\n",
    "    \n",
    "    frases_final = frases_final[[\"ParticipantMD5\", \"ItemNumber\", \"Classificacao\", \"Tempo_Gasto\", \"Timestamp\"]]\n",
    "    \n",
    "    return frases_final, genero_data\n",
    "\n",
    "def resolver_empates(df_original, todas_classificacoes):\n",
    "    \"\"\"\n",
    "    Resolve empates nas classificações, buscando classificações adicionais quando necessário.\n",
    "    Apenas considera empates quando há exatamente duas classificações com 2 ocorrências cada (2-2).\n",
    "    \n",
    "    Args:\n",
    "        df_original (DataFrame): DataFrame com as classificações originais\n",
    "        todas_classificacoes (DataFrame): Todas as classificações disponíveis\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (DataFrame com empates resolvidos, DataFrame com frases desempatadas)\n",
    "    \"\"\"\n",
    "    df_resolvido = df_original.copy()\n",
    "    frases_desempatadas = []\n",
    "    \n",
    "    # Itera sobre cada linha para verificar empates\n",
    "    for idx, row in df_original.iterrows():\n",
    "        item_number = row[\"ItemNumber\"]\n",
    "        frase = row[\"frase\"] if \"frase\" in row else f\"Frase {item_number}\"\n",
    "        \n",
    "        # Verifica empate nas classificações femininas\n",
    "        class_fem = [\n",
    "            row[\"f1_class\"], \n",
    "            row[\"f2_class\"], \n",
    "            row[\"f3_class\"], \n",
    "            row[\"f4_class\"]\n",
    "        ]\n",
    "        class_fem_validas = [c for c in class_fem if pd.notna(c)]\n",
    "        \n",
    "        tem_empate_fem = verificar_empate_exato(class_fem_validas)\n",
    "        \n",
    "        if tem_empate_fem:\n",
    "            # Busca classificações adicionais de mulheres para esta frase\n",
    "            classificacoes_adicionais_fem = todas_classificacoes[\n",
    "                (todas_classificacoes[\"ItemNumber\"] == item_number) & \n",
    "                (todas_classificacoes[\"GeneroCod\"] == \"f\") &\n",
    "                (~todas_classificacoes[\"ParticipantMD5\"].isin(df_original.columns))\n",
    "            ].sort_values(\"Timestamp\")\n",
    "            \n",
    "            if not classificacoes_adicionais_fem.empty:\n",
    "                # Substitui a última classificação pela próxima disponível\n",
    "                proxima_class = classificacoes_adicionais_fem.iloc[0][\"Classificacao\"]\n",
    "                proxima_tempo = classificacoes_adicionais_fem.iloc[0][\"Tempo_Gasto\"]\n",
    "                \n",
    "                # Guarda as classificações originais para o relatório\n",
    "                class_fem_orig = class_fem.copy()\n",
    "                \n",
    "                # Substitui a classificação\n",
    "                df_resolvido.at[idx, \"f4_class\"] = proxima_class\n",
    "                df_resolvido.at[idx, \"f4_tempo\"] = proxima_tempo\n",
    "                \n",
    "                # Verifica se ainda há empate após a substituição\n",
    "                novas_class_fem = [\n",
    "                    df_resolvido.at[idx, \"f1_class\"],\n",
    "                    df_resolvido.at[idx, \"f2_class\"],\n",
    "                    df_resolvido.at[idx, \"f3_class\"],\n",
    "                    df_resolvido.at[idx, \"f4_class\"]\n",
    "                ]\n",
    "                novas_class_fem_validas = [c for c in novas_class_fem if pd.notna(c)]\n",
    "                \n",
    "                tem_empate_agora = verificar_empate_exato(novas_class_fem_validas)\n",
    "                \n",
    "                if not tem_empate_agora:\n",
    "                    # Desempate bem-sucedido\n",
    "                    frases_desempatadas.append({\n",
    "                        \"ItemNumber\": item_number,\n",
    "                        \"frase\": frase,\n",
    "                        \"genero\": \"feminino\",\n",
    "                        \"class_originais\": str(class_fem_orig),\n",
    "                        \"class_novas\": str(novas_class_fem),\n",
    "                        \"classificacao_substituida\": proxima_class\n",
    "                    })\n",
    "        \n",
    "        # Verifica empate nas classificações masculinas\n",
    "        class_masc = [\n",
    "            row[\"m1_class\"], \n",
    "            row[\"m2_class\"], \n",
    "            row[\"m3_class\"], \n",
    "            row[\"m4_class\"]\n",
    "        ]\n",
    "        class_masc_validas = [c for c in class_masc if pd.notna(c)]\n",
    "        \n",
    "        tem_empate_masc = verificar_empate_exato(class_masc_validas)\n",
    "        \n",
    "        if tem_empate_masc:\n",
    "            # Busca classificações adicionais de homens para esta frase\n",
    "            classificacoes_adicionais_masc = todas_classificacoes[\n",
    "                (todas_classificacoes[\"ItemNumber\"] == item_number) & \n",
    "                (todas_classificacoes[\"GeneroCod\"] == \"m\") &\n",
    "                (~todas_classificacoes[\"ParticipantMD5\"].isin(df_original.columns))\n",
    "            ].sort_values(\"Timestamp\")\n",
    "            \n",
    "            if not classificacoes_adicionais_masc.empty:\n",
    "                # Substitui a última classificação pela próxima disponível\n",
    "                proxima_class = classificacoes_adicionais_masc.iloc[0][\"Classificacao\"]\n",
    "                proxima_tempo = classificacoes_adicionais_masc.iloc[0][\"Tempo_Gasto\"]\n",
    "                \n",
    "                # Guarda as classificações originais para o relatório\n",
    "                class_masc_orig = class_masc.copy()\n",
    "                \n",
    "                # Substitui a classificação\n",
    "                df_resolvido.at[idx, \"m4_class\"] = proxima_class\n",
    "                df_resolvido.at[idx, \"m4_tempo\"] = proxima_tempo\n",
    "                \n",
    "                # Verifica se ainda há empate após a substituição\n",
    "                novas_class_masc = [\n",
    "                    df_resolvido.at[idx, \"m1_class\"],\n",
    "                    df_resolvido.at[idx, \"m2_class\"],\n",
    "                    df_resolvido.at[idx, \"m3_class\"],\n",
    "                    df_resolvido.at[idx, \"m4_class\"]\n",
    "                ]\n",
    "                novas_class_masc_validas = [c for c in novas_class_masc if pd.notna(c)]\n",
    "                \n",
    "                tem_empate_agora = verificar_empate_exato(novas_class_masc_validas)\n",
    "                \n",
    "                if not tem_empate_agora:\n",
    "                    # Desempate bem-sucedido\n",
    "                    frases_desempatadas.append({\n",
    "                        \"ItemNumber\": item_number,\n",
    "                        \"frase\": frase,\n",
    "                        \"genero\": \"masculino\",\n",
    "                        \"class_originais\": str(class_masc_orig),\n",
    "                        \"class_novas\": str(novas_class_masc),\n",
    "                        \"classificacao_substituida\": proxima_class\n",
    "                    })\n",
    "    \n",
    "    # Recalcula as classificações majoritárias após resolver os empates\n",
    "    def majoritaria(row, prefixo):\n",
    "        colunas = [f\"{prefixo}{i}_class\" for i in range(1, 5)]\n",
    "        respostas = [row[col] for col in colunas if pd.notna(row[col])]\n",
    "        if respostas:\n",
    "            return Counter(respostas).most_common(1)[0][0]\n",
    "        return None\n",
    "            \n",
    "    def contar_iguais_majoritaria(row, prefixo, majoritaria):\n",
    "        colunas = [f\"{prefixo}{i}_class\" for i in range(1, 5)]\n",
    "        return sum(1 for col in colunas if pd.notna(row[col]) and row[col] == row[majoritaria])\n",
    "            \n",
    "    df_resolvido[\"cla_maj_femi\"] = df_resolvido.apply(lambda row: majoritaria(row, \"f\"), axis=1)\n",
    "    df_resolvido[\"cla_maj_masc\"] = df_resolvido.apply(lambda row: majoritaria(row, \"m\"), axis=1)\n",
    "    \n",
    "    df_resolvido[\"qtd_maj_femi\"] = df_resolvido.apply(\n",
    "        lambda row: contar_iguais_majoritaria(row, \"f\", \"cla_maj_femi\"), axis=1\n",
    "    )\n",
    "    \n",
    "    df_resolvido[\"qtd_maj_masc\"] = df_resolvido.apply(\n",
    "        lambda row: contar_iguais_majoritaria(row, \"m\", \"cla_maj_masc\"), axis=1\n",
    "    )\n",
    "    \n",
    "    # Cria DataFrame com as frases desempatadas\n",
    "    df_desempatadas = pd.DataFrame(frases_desempatadas)\n",
    "    \n",
    "    return df_resolvido, df_desempatadas\n",
    "\n",
    "def salvar_csv_com_frases_protegidas(df, output_path):\n",
    "    \"\"\"\n",
    "    Salva o DataFrame como CSV com aspas protegendo a coluna de frases.\n",
    "    \n",
    "    Args:\n",
    "        df (DataFrame): DataFrame a ser salvo\n",
    "        output_path (str): Caminho para o arquivo de saída\n",
    "    \"\"\"\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\",\".join(df.columns.tolist()) + \"\\n\")\n",
    "        for _, row in df.iterrows():\n",
    "            linha = []\n",
    "            for col in df.columns:\n",
    "                val = row[col]\n",
    "                if col == \"frase\":\n",
    "                    val = str(val)\n",
    "                    if not (val.startswith('\"') and val.endswith('\"')):\n",
    "                        val = f'\"{val}\"'\n",
    "                linha.append(str(val))\n",
    "            f.write(\",\".join(linha) + \"\\n\")\n",
    "    \n",
    "    print(f\"Arquivo salvo em: {output_path}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Função principal que orquestra todo o processamento.\n",
    "    \"\"\"\n",
    "    # Definição de caminhos\n",
    "    log_folder = \"logs/logs_brutos\"\n",
    "    log_processado_path = \"dados/MQD_1465_log_processado.csv\"\n",
    "    output_desempatado_path = \"dados/MQD_1465_desempatado.csv\"\n",
    "    output_frases_desempatadas_path = \"dados/frases_desempatadas.csv\"\n",
    "    \n",
    "    # Etapa 1: Carregar o arquivo de logs processados\n",
    "    print(\"Etapa 1: Carregando arquivo de logs processados...\")\n",
    "    df_processado = carregar_arquivo_seguro(log_processado_path)\n",
    "    print(f\"Carregados {len(df_processado)} registros do arquivo de logs processados.\")\n",
    "    \n",
    "    # Etapa 2: Carregar todos os logs brutos para buscar classificações adicionais\n",
    "    print(\"\\nEtapa 2: Carregando logs brutos para buscar classificações adicionais...\")\n",
    "    todas_classificacoes = carregar_logs_brutos(log_folder)\n",
    "    print(f\"Carregadas {len(todas_classificacoes)} classificações dos logs brutos.\")\n",
    "    \n",
    "    # Etapa 3: Resolver empates\n",
    "    print(\"\\nEtapa 3: Resolvendo empates nas classificações...\")\n",
    "    df_desempatado, frases_desempatadas = resolver_empates(df_processado, todas_classificacoes)\n",
    "         \n",
    "    # Etapa 4: Salvar resultados\n",
    "    print(\"\\nEtapa 4: Salvando resultados...\")\n",
    "    salvar_csv_com_frases_protegidas(df_desempatado, output_desempatado_path)\n",
    "\n",
    "    # Estatísticas adicionais\n",
    "    frases_empate_fem = []\n",
    "    frases_empate_masc = []\n",
    "\n",
    "    # Identifica frases que ainda estão com empate\n",
    "    for idx, row in df_desempatado.iterrows():\n",
    "        item_number = row[\"ItemNumber\"]\n",
    "        \n",
    "        # Verifica empate nas classificações femininas\n",
    "        class_fem = [\n",
    "            row[\"f1_class\"], \n",
    "            row[\"f2_class\"], \n",
    "            row[\"f3_class\"], \n",
    "            row[\"f4_class\"]\n",
    "        ]\n",
    "        class_fem_validas = [c for c in class_fem if pd.notna(c)]\n",
    "        \n",
    "        if verificar_empate_exato(class_fem_validas):\n",
    "            frases_empate_fem.append(item_number)\n",
    "        \n",
    "        # Verifica empate nas classificações masculinas\n",
    "        class_masc = [\n",
    "            row[\"m1_class\"], \n",
    "            row[\"m2_class\"], \n",
    "            row[\"m3_class\"], \n",
    "            row[\"m4_class\"]\n",
    "        ]\n",
    "        class_masc_validas = [c for c in class_masc if pd.notna(c)]\n",
    "        \n",
    "        if verificar_empate_exato(class_masc_validas):\n",
    "            frases_empate_masc.append(item_number)\n",
    "\n",
    "    if not frases_desempatadas.empty:\n",
    "        frases_desempatadas.to_csv(output_frases_desempatadas_path, index=False)\n",
    "        print(f\"Frases desempatadas salvas em: {output_frases_desempatadas_path}\")\n",
    "        \n",
    "        # Estatísticas por gênero\n",
    "        desempates_fem = frases_desempatadas[frases_desempatadas[\"genero\"] == \"feminino\"]\n",
    "        desempates_masc = frases_desempatadas[frases_desempatadas[\"genero\"] == \"masculino\"]\n",
    "        \n",
    "        print(f\"\\nEstatísticas de classificação:\")\n",
    "        print(f\"- Frases empatadas femininas: {len(frases_empate_fem)}\")\n",
    "        print(f\"- Frases empatadas masculinas: {len(frases_empate_masc)}\")\n",
    "        print(f\"- Frases desempatadas femininas: {len(desempates_fem)}\")\n",
    "        print(f\"- Frases desempatadas masculinas: {len(desempates_masc)}\")\n",
    "        print(f\"- Total de frases ainda empatadas: {len(frases_empate_fem) + len(frases_empate_masc)}\")\n",
    "        print(f\"- Total de frases com classes majoritárias definidas: {len(df_desempatado) - (len(frases_empate_fem) + len(frases_empate_masc))}\")\n",
    "    else:\n",
    "        print(\"Nenhuma frase foi desempatada.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
