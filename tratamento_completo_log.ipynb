{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b549a26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etapa 1: Processando logs brutos...\n",
      "Processando arquivo: results_prod.csv\n",
      "Processando arquivo: results_prod (1).csv\n",
      "Processando arquivo: results_prod (2).csv\n",
      "Processando arquivo: results_prod (3).csv\n",
      "Processando arquivo: results_prod (4).csv\n",
      "Processando arquivo: results_prod (5).csv\n",
      "Processando arquivo: results_prod (6).csv\n",
      "Processando arquivo: results_prod (7).csv\n",
      "Processando arquivo: results_prod (8).csv\n",
      "Processando arquivo: results_prod (9).csv\n",
      "Logs processados salvos em: dados/MQD_1465_log_original.csv\n",
      "\n",
      "Etapa 2: Combinando com arquivo de frases randomizadas...\n",
      "\n",
      "Etapa 3: Salvando resultado final...\n",
      "Arquivo salvo em: dados/MQD_1465_log_processado.csv\n",
      "\n",
      "Processamento concluído. Total de 1465 registros processados.\n",
      "Distribuição de classificações femininas: {'positiva': 514, 'negativa': 503, 'neutra': 448}\n",
      "Distribuição de classificações masculinas: {'positiva': 619, 'negativa': 514, 'neutra': 332}\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Processamento de Logs PCIbex - Análise de Sentimentos\n",
    "Este script processa logs brutos do PCIbex para um experimento de classificação de frases,\n",
    "extrai informações sobre gênero dos participantes, suas classificações e tempos de resposta,\n",
    "e combina os resultados com o arquivo de frases randomizadas.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "from collections import Counter\n",
    "\n",
    "def process_log_file(file_path):\n",
    "    \"\"\"\n",
    "    Processa um arquivo de log do PCIbex e extrai informações relevantes.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Caminho para o arquivo de log\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (DataFrame com classificações e tempos, DataFrame com dados de gênero)\n",
    "    \"\"\"\n",
    "    # === 1. Leitura do arquivo CSV ===\n",
    "    # Pula as primeiras 19 linhas que contêm metadados não relevantes\n",
    "    df = pd.read_csv(file_path, skiprows=19, header=None)\n",
    "    \n",
    "    # Define nomes para as colunas\n",
    "    df.columns = [\n",
    "        \"ReceptionTime\", \"ParticipantMD5\", \"Controller\", \"ItemNumber\", \"InnerElementNumber\",\n",
    "        \"Label\", \"Group\", \"PennElementType\", \"PennElementName\", \"Parameter\",\n",
    "        \"Value\", \"EventTime\", \"Comments\"\n",
    "    ]\n",
    "    \n",
    "    # Remove linhas de comentários e labels irrelevantes\n",
    "    df = df[~df[\"ReceptionTime\"].astype(str).str.startswith(\"#\")].copy()\n",
    "    df = df[~df[\"Label\"].isin([\"TCLE\", \"instrucoes\", \"agradecimento\"])]\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # === 2. Extração de dados de gênero ===\n",
    "    genero_data = df[\n",
    "        (df[\"Label\"] == \"genero\") &\n",
    "        (df[\"PennElementName\"] == \"selecionaGenero\") &\n",
    "        (df[\"Parameter\"] == \"Selected\")\n",
    "    ][[\"ParticipantMD5\", \"Value\"]].rename(columns={\"Value\": \"Genero\"}).drop_duplicates()\n",
    "    \n",
    "    # === 3. Processamento do bloco de frases ===\n",
    "    # Extrai as classificações (positiva, negativa, neutra)\n",
    "    selecoes_frases = df[\n",
    "        (df[\"Label\"] == \"frases\") &\n",
    "        (df[\"Parameter\"] == \"Selection\")\n",
    "    ].copy()\n",
    "    \n",
    "    # Ajusta o ItemNumber (subtrai 3 para alinhar com a numeração correta)\n",
    "    selecoes_frases[\"ItemNumber\"] = selecoes_frases[\"ItemNumber\"].astype(int) - 3\n",
    "    selecoes_frases = selecoes_frases[[\"ParticipantMD5\", \"ItemNumber\", \"Value\", \"EventTime\"]]\n",
    "    selecoes_frases.columns = [\"ParticipantMD5\", \"ItemNumber\", \"Classificacao\", \"Timestamp\"]\n",
    "    \n",
    "    # Obtém tempos de início e fim para calcular o tempo gasto\n",
    "    start_trials = df[(df[\"Label\"] == \"frases\") & (df[\"Parameter\"] == \"_Trial_\") & (df[\"Value\"] == \"Start\")]\n",
    "    end_trials = df[(df[\"Label\"] == \"frases\") & (df[\"Parameter\"] == \"_Trial_\") & (df[\"Value\"] == \"End\")]\n",
    "    \n",
    "    start_trials = start_trials[[\"ParticipantMD5\", \"ItemNumber\", \"EventTime\"]].copy()\n",
    "    end_trials = end_trials[[\"ParticipantMD5\", \"ItemNumber\", \"EventTime\"]].copy()\n",
    "    \n",
    "    start_trials[\"ItemNumber\"] = start_trials[\"ItemNumber\"].astype(int) - 3\n",
    "    end_trials[\"ItemNumber\"] = end_trials[\"ItemNumber\"].astype(int) - 3\n",
    "    \n",
    "    start_trials.rename(columns={\"EventTime\": \"StartTime\"}, inplace=True)\n",
    "    end_trials.rename(columns={\"EventTime\": \"EndTime\"}, inplace=True)\n",
    "    \n",
    "    # Calcula o tempo gasto em cada classificação (em segundos)\n",
    "    frases_final = selecoes_frases.merge(start_trials, on=[\"ParticipantMD5\", \"ItemNumber\"], how=\"left\")\n",
    "    frases_final = frases_final.merge(end_trials, on=[\"ParticipantMD5\", \"ItemNumber\"], how=\"left\")\n",
    "    frases_final[\"Tempo_Gasto\"] = ((frases_final[\"EndTime\"] - frases_final[\"StartTime\"]) / 1000).round(3)\n",
    "    \n",
    "    frases_final = frases_final[[\"ParticipantMD5\", \"ItemNumber\", \"Classificacao\", \"Tempo_Gasto\", \"Timestamp\"]]\n",
    "    \n",
    "    return frases_final, genero_data\n",
    "\n",
    "def process_all_logs(log_folder, base_filename=\"results_prod\", num_files=10):\n",
    "    \"\"\"\n",
    "    Processa todos os arquivos de log e seleciona 4 participantes de cada gênero por arquivo.\n",
    "    \n",
    "    Args:\n",
    "        log_folder (str): Pasta contendo os logs brutos\n",
    "        base_filename (str): Nome base dos arquivos de log\n",
    "        num_files (int): Número de arquivos numerados a processar\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Dados processados de todos os arquivos\n",
    "    \"\"\"\n",
    "    all_processed_data = []\n",
    "    base_item_number = 0\n",
    "    \n",
    "    # Lista de arquivos a processar (arquivo base + numerados)\n",
    "    files_to_process = [f\"{base_filename}.csv\"] + [f\"{base_filename} ({i}).csv\" for i in range(1, num_files)]\n",
    "    \n",
    "    for filename in files_to_process:\n",
    "        file_path = os.path.join(log_folder, filename)\n",
    "        if not os.path.exists(file_path):\n",
    "            continue\n",
    "            \n",
    "        print(f\"Processando arquivo: {filename}\")\n",
    "        \n",
    "        try:\n",
    "            # Processa o arquivo atual\n",
    "            frases, generos = process_log_file(file_path)\n",
    "            \n",
    "            # Adiciona offset ao ItemNumber para arquivos subsequentes\n",
    "            frases[\"ItemNumber\"] = frases[\"ItemNumber\"] + base_item_number\n",
    "            \n",
    "            # Codifica o gênero (m/f)\n",
    "            generos[\"GeneroCod\"] = generos[\"Genero\"].str.lower().map(lambda g: \"m\" if \"masculino\" in g else \"f\")\n",
    "            \n",
    "            # Seleciona 4 participantes de cada gênero para este arquivo\n",
    "            ids_masculinos = generos[generos[\"GeneroCod\"] == \"m\"].head(4)[\"ParticipantMD5\"].tolist()\n",
    "            ids_femininos = generos[generos[\"GeneroCod\"] == \"f\"].head(4)[\"ParticipantMD5\"].tolist()\n",
    "            ids_selecionados = ids_femininos + ids_masculinos\n",
    "            \n",
    "            frases_filtradas = frases[frases[\"ParticipantMD5\"].isin(ids_selecionados)].copy()\n",
    "            \n",
    "            # Cria tabelas pivot com identificadores genéricos\n",
    "            pivot_class = frases_filtradas.pivot_table(\n",
    "                index=\"ItemNumber\",\n",
    "                columns=\"ParticipantMD5\",\n",
    "                values=\"Classificacao\",\n",
    "                aggfunc=\"first\"\n",
    "            )\n",
    "            \n",
    "            pivot_time = frases_filtradas.pivot_table(\n",
    "                index=\"ItemNumber\",\n",
    "                columns=\"ParticipantMD5\",\n",
    "                values=\"Tempo_Gasto\",\n",
    "                aggfunc=\"first\"\n",
    "            )\n",
    "            \n",
    "            # Renomeia colunas para identificadores genéricos (f1, f2, m1, m2, etc.)\n",
    "            fem_cols = [col for col in pivot_class.columns if generos.loc[generos[\"ParticipantMD5\"] == col, \"GeneroCod\"].iloc[0] == \"f\"]\n",
    "            masc_cols = [col for col in pivot_class.columns if generos.loc[generos[\"ParticipantMD5\"] == col, \"GeneroCod\"].iloc[0] == \"m\"]\n",
    "            \n",
    "            rename_dict_class = {}\n",
    "            rename_dict_time = {}\n",
    "            \n",
    "            for i, col in enumerate(fem_cols[:4], 1):\n",
    "                rename_dict_class[col] = f\"f{i}_class\"\n",
    "                rename_dict_time[col] = f\"f{i}_tempo\"\n",
    "                \n",
    "            for i, col in enumerate(masc_cols[:4], 1):\n",
    "                rename_dict_class[col] = f\"m{i}_class\"\n",
    "                rename_dict_time[col] = f\"m{i}_tempo\"\n",
    "                \n",
    "            pivot_class = pivot_class.rename(columns=rename_dict_class)\n",
    "            pivot_time = pivot_time.rename(columns=rename_dict_time)\n",
    "            \n",
    "            frases_limitadas = pd.concat([pivot_class, pivot_time], axis=1).reset_index()\n",
    "            \n",
    "            # Calcula classificações majoritárias\n",
    "            def majoritaria(row, prefixo):\n",
    "                colunas = [f\"{prefixo}{i}_class\" for i in range(1, 5)]\n",
    "                respostas = [row[col] for col in colunas if pd.notna(row[col])]\n",
    "                if respostas:\n",
    "                    return Counter(respostas).most_common(1)[0][0]\n",
    "                return None\n",
    "                \n",
    "            def contar_iguais_majoritaria(row, prefixo, majoritaria):\n",
    "                colunas = [f\"{prefixo}{i}_class\" for i in range(1, 5)]\n",
    "                return sum(1 for col in colunas if pd.notna(row[col]) and row[col] == row[majoritaria])\n",
    "                \n",
    "            frases_limitadas[\"cla_maj_femi\"] = frases_limitadas.apply(lambda row: majoritaria(row, \"f\"), axis=1)\n",
    "            frases_limitadas[\"cla_maj_masc\"] = frases_limitadas.apply(lambda row: majoritaria(row, \"m\"), axis=1)\n",
    "            \n",
    "            frases_limitadas[\"qtd_maj_femi\"] = frases_limitadas.apply(\n",
    "                lambda row: contar_iguais_majoritaria(row, \"f\", \"cla_maj_femi\"), axis=1\n",
    "            )\n",
    "            \n",
    "            frases_limitadas[\"qtd_maj_masc\"] = frases_limitadas.apply(\n",
    "                lambda row: contar_iguais_majoritaria(row, \"m\", \"cla_maj_masc\"), axis=1\n",
    "            )\n",
    "            \n",
    "            # Organiza as colunas\n",
    "            colunas_final = [\n",
    "                \"ItemNumber\",\n",
    "                # Majoritárias e quantidades\n",
    "                \"cla_maj_femi\", \"qtd_maj_femi\",\n",
    "                \"cla_maj_masc\", \"qtd_maj_masc\",\n",
    "                # Classificações femininas\n",
    "                \"f1_class\", \"f2_class\", \"f3_class\", \"f4_class\",\n",
    "                # Classificações masculinas\n",
    "                \"m1_class\", \"m2_class\", \"m3_class\", \"m4_class\",\n",
    "                # Colunas de tempo\n",
    "                \"f1_tempo\", \"f2_tempo\", \"f3_tempo\", \"f4_tempo\",\n",
    "                \"m1_tempo\", \"m2_tempo\", \"m3_tempo\", \"m4_tempo\"\n",
    "            ]\n",
    "            \n",
    "            frases_formatadas = frases_limitadas[colunas_final]\n",
    "            all_processed_data.append(frases_formatadas)\n",
    "            \n",
    "            # Atualiza base_item_number para o próximo arquivo\n",
    "            base_item_number = frases[\"ItemNumber\"].max()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao processar {filename}: {str(e)}\")\n",
    "            \n",
    "    if all_processed_data:\n",
    "        # Combina todos os resultados\n",
    "        resultado_final = pd.concat(all_processed_data, ignore_index=True)\n",
    "        return resultado_final\n",
    "    else:\n",
    "        print(\"Nenhum arquivo foi processado com sucesso!\")\n",
    "        return None\n",
    "\n",
    "def merge_with_phrases(log_df, phrases_file):\n",
    "    \"\"\"\n",
    "    Combina o log processado com o arquivo de frases randomizadas.\n",
    "    \n",
    "    Args:\n",
    "        log_df (DataFrame): DataFrame com os logs processados\n",
    "        phrases_file (str): Caminho para o arquivo de frases randomizadas\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: DataFrame combinado com frases e classificações\n",
    "    \"\"\"\n",
    "    # Detecção automática do delimitador do arquivo de frases\n",
    "    with open(phrases_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        sample = f.read(2048)\n",
    "    \n",
    "    sniffer = csv.Sniffer()\n",
    "    dialect = sniffer.sniff(sample)\n",
    "    \n",
    "    # Lê o arquivo de frases randomizadas\n",
    "    df_randomizado = pd.read_csv(phrases_file, sep=dialect.delimiter)\n",
    "    \n",
    "    # Remove espaços em branco dos nomes das colunas\n",
    "    df_randomizado.columns = df_randomizado.columns.str.strip()\n",
    "    log_df.columns = log_df.columns.str.strip()\n",
    "    \n",
    "    # Garante a coluna ID_Random\n",
    "    if \"ID_Random\" not in df_randomizado.columns:\n",
    "        df_randomizado.insert(0, \"ID_Random\", range(1, len(df_randomizado) + 1))\n",
    "    \n",
    "    # Merge pelo índice\n",
    "    df_log_completo = pd.merge(\n",
    "        log_df,\n",
    "        df_randomizado[[\"ID_Random\", \"frase\"]],\n",
    "        left_on=\"ItemNumber\",\n",
    "        right_on=\"ID_Random\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    \n",
    "    # Reorganiza as colunas\n",
    "    colunas = df_log_completo.columns.tolist()\n",
    "    idx_item = colunas.index(\"ItemNumber\")\n",
    "    colunas_organizadas = colunas[:idx_item + 1] + [\"frase\"] + [col for col in colunas if col not in [\"ItemNumber\", \"frase\", \"ID_Random\"]]\n",
    "    df_log_completo = df_log_completo[colunas_organizadas]\n",
    "    \n",
    "    return df_log_completo\n",
    "\n",
    "def save_csv_with_protected_phrases(df, output_path):\n",
    "    \"\"\"\n",
    "    Salva o DataFrame como CSV com aspas protegendo a coluna de frases.\n",
    "    \n",
    "    Args:\n",
    "        df (DataFrame): DataFrame a ser salvo\n",
    "        output_path (str): Caminho para o arquivo de saída\n",
    "    \"\"\"\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\",\".join(df.columns.tolist()) + \"\\n\")\n",
    "        for _, row in df.iterrows():\n",
    "            linha = []\n",
    "            for col in df.columns:\n",
    "                val = row[col]\n",
    "                if col == \"frase\":\n",
    "                    val = str(val)\n",
    "                    if not (val.startswith('\"') and val.endswith('\"')):\n",
    "                        val = f'\"{val}\"'\n",
    "                linha.append(str(val))\n",
    "            f.write(\",\".join(linha) + \"\\n\")\n",
    "    \n",
    "    print(f\"Arquivo salvo em: {output_path}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Função principal que orquestra todo o processamento.\n",
    "    \"\"\"\n",
    "    # Definição de caminhos\n",
    "    log_folder = \"logs/logs_brutos\"\n",
    "    randomizado_path = \"dados/MQD_1465_randomizado.csv\"\n",
    "    output_log_path = \"dados/MQD_1465_log_original.csv\"\n",
    "    output_final_path = \"dados/MQD_1465_log_processado.csv\"\n",
    "    \n",
    "    # Etapa 1: Processar todos os logs\n",
    "    print(\"Etapa 1: Processando logs brutos...\")\n",
    "    resultado_logs = process_all_logs(log_folder)\n",
    "    \n",
    "    if resultado_logs is not None:\n",
    "        # Salva o resultado intermediário (logs processados sem frases)\n",
    "        resultado_logs.to_csv(output_log_path, index=False)\n",
    "        print(f\"Logs processados salvos em: {output_log_path}\")\n",
    "        \n",
    "        # Etapa 2: Combinar com o arquivo de frases\n",
    "        print(\"\\nEtapa 2: Combinando com arquivo de frases randomizadas...\")\n",
    "        resultado_final = merge_with_phrases(resultado_logs, randomizado_path)\n",
    "        \n",
    "        # Etapa 3: Salvar o resultado final com frases protegidas\n",
    "        print(\"\\nEtapa 3: Salvando resultado final...\")\n",
    "        save_csv_with_protected_phrases(resultado_final, output_final_path)\n",
    "        \n",
    "        # Exibir estatísticas finais\n",
    "        print(f\"\\nProcessamento concluído. Total de {len(resultado_final)} registros processados.\")\n",
    "        print(f\"Distribuição de classificações femininas: {resultado_final['cla_maj_femi'].value_counts().to_dict()}\")\n",
    "        print(f\"Distribuição de classificações masculinas: {resultado_final['cla_maj_masc'].value_counts().to_dict()}\")\n",
    "    else:\n",
    "        print(\"Não foi possível processar os logs. Verifique os arquivos de entrada.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
